{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Ab hier unser Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'churn-train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4420ebd36cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'timezone_cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tenure_visit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'branch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abc_cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abc_detailed_cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_no_main_cat_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_no_main_cat_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_no_main_cat_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_no_main_cat_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_no_main_cat_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_articles_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_articles_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'churn_flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_visits_per_chg_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_sales_per_chg_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visit_gap_ratio_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visit_gap_ratio_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visit_gap_ratio_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_days_between_visits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_st_visits_per_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_st_visits_per_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'basket_spend'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'basket_spend_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'basket_spend_per_chg_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f_sales_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_visits_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_sales_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p_visits_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p_sales_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_visits_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_sales_per_chg_6_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f_visits_per_chg_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_visits_per_chg_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_sales_per_chg_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p_visits_per_chg_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p_sales_per_chg_q1_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'consistency_mnth_cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'consistency_qtr_cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distinct_weeks_bought'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'expect_visit_flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'expect_visit_flag2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_sales_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'margin_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_sales_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_promo_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_promo_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_colli_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_pieces_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales_last_model_period_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visits_last_model_period_per'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distinct_stores'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recency'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'margin_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_visits_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_visits_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_visits_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visit_gap_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visit_gap_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visit_gap_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_sales_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_sales_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_sales_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_sales_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_sales_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_promo_sales'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_promo_sales'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_visits_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_visits_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_visits_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_visits_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'promo_visits_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_sales_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_sales_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_sales_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_sales_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_sales_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_visits_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_visits_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_visits_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nf_visits_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_sales_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_sales_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_sales_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_visits_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_visits_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_visits_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pieces'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_colli'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'food_pieces'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'colli_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'colli_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_store_visits_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_store_visits_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_store_visits_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visits_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visits_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visits_q3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visits_q4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visits_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visits_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visits_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales_q3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales_q4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_visits_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_visits_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_visits_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_visits_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_sales_q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_sales_q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_sales_th'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_sales_lh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_sales_1y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prediction_week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIRIS_TRAIN_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIRIS_TEST_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'churn-train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Import the needed libraries\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import tensorflow as tf  \n",
    "import urllib.request as request  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download dataset\n",
    "IRIS_TRAIN_URL = \"churn-train.csv\"  \n",
    "IRIS_TEST_URL = \"churn-test.csv\"\n",
    "\n",
    "names = ['churn_flag', 'timezone_cd', 'tenure_visit', 'branch', 'abc_cd', 'abc_detailed_cd', 'avg_no_main_cat_1y', 'avg_no_main_cat_q1', 'avg_no_main_cat_q2', 'avg_no_main_cat_th', 'avg_no_main_cat_lh', 'avg_articles_6_6', 'avg_articles_q1_q2', 'ret_visits_per_chg_q1_q2', 'ret_sales_per_chg_q1_q2', 'visit_gap_ratio_th', 'visit_gap_ratio_1y', 'visit_gap_ratio_per_chg_6_6', 'avg_days_between_visits', 'home_st_visits_per_q1', 'home_st_visits_per_6_6', 'basket_spend', 'basket_spend_per_chg_6_6', 'basket_spend_per_chg_q1_q2', 'f_sales_per_chg_6_6', 'nf_visits_per_chg_6_6', 'nf_sales_per_chg_6_6', 'p_visits_per_chg_6_6', 'p_sales_per_chg_6_6', 'ret_visits_per_chg_6_6', 'ret_sales_per_chg_6_6', 'f_visits_per_chg_q1_q2', 'nf_visits_per_chg_q1_q2', 'nf_sales_per_chg_q1_q2', 'p_visits_per_chg_q1_q2', 'p_sales_per_chg_q1_q2', 'consistency_mnth_cd', 'consistency_qtr_cd', 'distinct_weeks_bought', 'expect_visit_flag', 'expect_visit_flag2', 'promo_sales_per', 'margin_per', 'food_sales_per', 'food_promo_per', 'nf_promo_per', 'food_colli_per', 'food_pieces_per', 'sales_last_model_period_per', 'visits_last_model_period_per', 'distinct_stores', 'recency', 'margin_1y', 'home_visits_q1', 'home_visits_lh', 'home_visits_th', 'visit_gap_th', 'visit_gap_lh', 'visit_gap_1y', 'promo_sales_1y', 'promo_sales_q1', 'promo_sales_q2', 'promo_sales_th', 'promo_sales_lh', 'nf_promo_sales', 'food_promo_sales', 'promo_visits_q1', 'promo_visits_q2', 'promo_visits_th', 'promo_visits_lh', 'promo_visits_1y', 'nf_sales_1y', 'nf_sales_q1', 'nf_sales_q2', 'nf_sales_th', 'nf_sales_lh', 'nf_visits_q1', 'nf_visits_q2', 'nf_visits_th', 'nf_visits_lh', 'food_sales_1y', 'food_sales_th', 'food_sales_lh', 'food_visits_1y', 'food_visits_q1', 'food_visits_q2', 'pieces', 'food_colli', 'food_pieces', 'colli_1y', 'colli_q1', 'home_store_visits_q1', 'home_store_visits_th', 'home_store_visits_lh', 'visits_q1', 'visits_q2', 'visits_q3', 'visits_q4', 'visits_1y', 'visits_th', 'visits_lh', 'sales_1y', 'sales_q1', 'sales_q2', 'sales_q3', 'sales_q4', 'sales_th', 'sales_lh', 'ret_visits_q1', 'ret_visits_q2', 'ret_visits_th', 'ret_visits_lh', 'ret_sales_q1', 'ret_sales_q2', 'ret_sales_th', 'ret_sales_lh', 'ret_sales_1y', 'prediction_week']  \n",
    "train = pd.read_csv(IRIS_TRAIN_URL, names=names, skiprows=0)  \n",
    "test = pd.read_csv(IRIS_TEST_URL, names=names, skiprows=0)\n",
    "\n",
    "print(test.head())\n",
    "\n",
    "# Train and test input data\n",
    "Xtrain = train.drop(\"churn_flag\", axis=1)  \n",
    "Xtest = test.drop(\"churn_flag\", axis=1)\n",
    "\n",
    "# Encode target values into binary ('one-hot' style) representation\n",
    "ytrain = pd.get_dummies(train.churn_flag)  \n",
    "ytest = pd.get_dummies(test.churn_flag)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create and train a tensorflow model of a neural network\n",
    "def create_train_model(hidden_nodes, num_iters):\n",
    "\n",
    "    # Reset the graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Placeholders for input and output data\n",
    "    X = tf.placeholder(shape=(365754, 117), dtype=tf.float64, name='X')\n",
    "    y = tf.placeholder(shape=(365754, 2), dtype=tf.float64, name='y')\n",
    "    \n",
    "    # Variables for two group of weights between the three layers of the network\n",
    "    W1 = tf.Variable(np.random.rand(117, hidden_nodes), dtype=tf.float64)\n",
    "    W2 = tf.Variable(np.random.rand(hidden_nodes, 2), dtype=tf.float64)\n",
    "\n",
    "    # Create the neural net graph\n",
    "    A1 = tf.sigmoid(tf.matmul(X, W1))\n",
    "    y_est = tf.sigmoid(tf.matmul(A1, W2))\n",
    "    \n",
    "    # Define a loss function\n",
    "    deltas = tf.square(y_est - y)\n",
    "    loss = tf.reduce_sum(deltas)\n",
    "\n",
    "    # Define a train operation to minimize the loss\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.005)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # Initialize variables and run session\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Go through num_iters iterations\n",
    "    for i in range(num_iters):\n",
    "        print(i)\n",
    "        sess.run(train, feed_dict={X: Xtrain, y: ytrain})\n",
    "        loss_plot[hidden_nodes].append(sess.run(loss, feed_dict={X: Xtrain.as_matrix(), y: ytrain.as_matrix()}))\n",
    "        weights1 = sess.run(W1)\n",
    "        weights2 = sess.run(W2)\n",
    "        \n",
    "    print(\"loss (hidden nodes: %d, iterations: %d): %.2f\" % (hidden_nodes, num_iters, loss_plot[hidden_nodes][-1]))\n",
    "    sess.close()\n",
    "    return weights1, weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Run the training for 3 different network architectures: (4-5-3) (4-10-3) (4-20-3)\n",
    "\n",
    "# Plot the loss function over iterations\n",
    "num_hidden_nodes = [10]#, 10, 20]\n",
    "loss_plot = {10: []}#, 10: [], 20: []}  \n",
    "weights1 = {10: None}#, 10: None, 20: None}  \n",
    "weights2 = {10: None}#, 10: None, 20: None}  \n",
    "num_iters = 20\n",
    "\n",
    "plt.figure(figsize=(12,8))  \n",
    "for hidden_nodes in num_hidden_nodes:  \n",
    "    weights1[hidden_nodes], weights2[hidden_nodes] = create_train_model(hidden_nodes, num_iters)\n",
    "    plt.plot(range(num_iters), loss_plot[hidden_nodes], label=\"nn: 4-%d-3\" % hidden_nodes)\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=12)  \n",
    "plt.ylabel('Loss', fontsize=12)  \n",
    "plt.legend(fontsize=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluate models on the test set\n",
    "X = tf.placeholder(shape=(121918, 117), dtype=tf.float64, name='X')  \n",
    "y = tf.placeholder(shape=(121918, 2), dtype=tf.float64, name='y')\n",
    "\n",
    "for hidden_nodes in num_hidden_nodes:\n",
    "\n",
    "    # Forward propagation\n",
    "    W1 = tf.Variable(weights1[hidden_nodes])\n",
    "    W2 = tf.Variable(weights2[hidden_nodes])\n",
    "    A1 = tf.sigmoid(tf.matmul(X, W1))\n",
    "    y_est = tf.sigmoid(tf.matmul(A1, W2))\n",
    "\n",
    "    # Calculate the predicted outputs\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        y_est_np = sess.run(y_est, feed_dict={X: Xtest, y: ytest})\n",
    "\n",
    "    # Calculate the prediction accuracy\n",
    "    correct = [estimate.argmax(axis=0) == target.argmax(axis=0) \n",
    "               for estimate, target in zip(y_est_np, ytest.as_matrix())]\n",
    "    accuracy = 100 * sum(correct) / len(correct)\n",
    "    print('Network architecture 50-%d-40, accuracy: %.2f%%' % (hidden_nodes, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
