{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.1.4-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: numpy>=1.9.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from keras)\n",
      "Requirement already up-to-date: scipy>=0.14 in /usr/local/envs/py2env/lib/python2.7/site-packages (from keras)\n",
      "Requirement already up-to-date: six>=1.9.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from keras)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading PyYAML-3.12.tar.gz (253kB)\n",
      "\u001b[K    100% |████████████████████████████████| 256kB 1.5MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/2c/f7/79/13f3a12cd723892437c0cfbde1230ab4d82947ff7b3839a4fc\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "  Found existing installation: PyYAML 3.11\n",
      "    Uninstalling PyYAML-3.11:\n",
      "      Successfully uninstalled PyYAML-3.11\n",
      "Successfully installed keras-2.1.4 pyyaml-3.12\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import h5py\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from pandas_gbq.gbq import GenericGBQException\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%sql --module letslookatthedata\n",
    "SELECT * FROM [metro-bi-dscustomer-internal:churn_nn_data.mv_ab_model_ads_build_sep] LIMIT 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "accessDenied: Access Denied: Table metro-bi-dscustomer-internal:churn_nn_data.mv_ab_model_ads_build_sep: The user 462605511119-compute@developer.gserviceaccount.com does not have permission to query table metro-bi-dscustomer-internal:churn_nn_data.mv_ab_model_ads_build_sep.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-72c4650e1fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchurn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletslookatthedata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mchurn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/datalab/bigquery/_query.pyc\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, start_row, max_rows, use_cache, dialect, billing_tier)\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mPandas\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtable\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbilling_tier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbilling_tier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/datalab/bigquery/_query.pyc\u001b[0m in \u001b[0;36mresults\u001b[0;34m(self, use_cache, dialect, billing_tier)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbilling_tier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbilling_tier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/datalab/bigquery/_query.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, table_name, table_mode, use_cache, priority, allow_large_results, dialect, billing_tier)\u001b[0m\n\u001b[1;32m    525\u001b[0m     job = self.execute_async(table_name=table_name, table_mode=table_mode, use_cache=use_cache,\n\u001b[1;32m    526\u001b[0m                              \u001b[0mpriority\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpriority\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_large_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_large_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                              dialect=dialect, billing_tier=billing_tier)\n\u001b[0m\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/datalab/bigquery/_query.pyc\u001b[0m in \u001b[0;36mexecute_async\u001b[0;34m(self, table_name, table_mode, use_cache, priority, allow_large_results, dialect, billing_tier)\u001b[0m\n\u001b[1;32m    491\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# The query was in error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_query_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_query_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: accessDenied: Access Denied: Table metro-bi-dscustomer-internal:churn_nn_data.mv_ab_model_ads_build_sep: The user 462605511119-compute@developer.gserviceaccount.com does not have permission to query table metro-bi-dscustomer-internal:churn_nn_data.mv_ab_model_ads_build_sep."
     ]
    }
   ],
   "source": [
    "churn = bq.Query(letslookatthedata).to_dataframe()\n",
    "churn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def query_gbq(query, project_id, **bq_query_config_args):\n",
    "    try:\n",
    "        data = pd.read_gbq(\n",
    "            query, project_id,\n",
    "            configuration=get_bq_query_config(project_id, **bq_query_config_args)\n",
    "        ) # \n",
    "    except GenericGBQException:\n",
    "        logging.warning(\n",
    "            \"Generic GBQ exception detected, probably because the intermediate data table already exists,\"\n",
    "            \"attempting to overwrite...\")\n",
    "        query_config = get_bq_query_config(project_id, **bq_query_config_args)\n",
    "        query_config['query'][\"writeDisposition\"] = \"WRITE_TRUNCATE\" # tells BQ to overwrite\n",
    "        data = pd.read_gbq(query, project_id, configuration=query_config)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_bq_query_config(\n",
    "    projectId, allowLargeResults=True, datasetId='churn_nn_data', tableId='mv_ab_model_ads_build_sep'\n",
    "):\n",
    "    return {\"query\": {\n",
    "        \"allowLargeResults\": allowLargeResults,\n",
    "        'destinationTable': {\n",
    "            'projectId': projectId,\n",
    "            'datasetId': datasetId,\n",
    "            'tableId': tableId\n",
    "        }\n",
    "    }}\n",
    "\n",
    "churn = query_gbq(\n",
    "    \"SELECT * FROM churn_nn_data.mv_ab_model_ads_build_sep LIMIT 100000000\", \n",
    "    \"metro-bi-dscustomer-internal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = churn.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "churn_normalized = pd.DataFrame(x_scaled)\n",
    "churn_normalized.columns = ['timezone_cd', 'tenure_date_created', 'tenure_visit', 'branch', 'abc_cd', 'abc_detailed_cd', 'avg_no_main_cat_1y', 'avg_no_main_cat_q1', 'avg_no_main_cat_q2', 'avg_no_main_cat_th', 'avg_no_main_cat_lh', 'avg_articles_6_6', 'avg_articles_q1_q2', 'churn_flag', 'growth_flag', 'decline_flag', 'ret_visits_per_chg_q1_q2', 'ret_sales_per_chg_q1_q2', 'visit_gap_ratio_th', 'visit_gap_ratio_1y', 'visit_gap_ratio_per_chg_6_6', 'avg_days_between_visits', 'home_st_visits_per_q1', 'home_st_visits_per_6_6', 'basket_spend', 'basket_spend_per_chg_6_6', 'basket_spend_per_chg_q1_q2', 'f_sales_per_chg_6_6', 'nf_visits_per_chg_6_6', 'nf_sales_per_chg_6_6', 'p_visits_per_chg_6_6', 'p_sales_per_chg_6_6', 'ret_visits_per_chg_6_6', 'ret_sales_per_chg_6_6', 'f_visits_per_chg_q1_q2', 'nf_visits_per_chg_q1_q2', 'nf_sales_per_chg_q1_q2', 'p_visits_per_chg_q1_q2', 'p_sales_per_chg_q1_q2', 'consistency_mnth_cd', 'consistency_qtr_cd', 'distinct_weeks_bought', 'expect_visit_flag', 'expect_visit_flag2', 'promo_sales_per', 'margin_per', 'coupon_disc_per', 'food_visits_per', 'food_sales_per', 'food_promo_per', 'nf_promo_per', 'food_colli_per', 'food_pieces_per', 'sales_last_model_period_per', 'visits_last_model_period_per', 'distinct_stores', 'recency', 'coupon_disc', 'margin_1y', 'home_visits_q1', 'home_visits_lh', 'home_visits_th', 'visit_gap_th', 'visit_gap_lh', 'visit_gap_1y', 'promo_sales_1y', 'promo_sales_q1', 'promo_sales_q2', 'promo_sales_th', 'promo_sales_lh', 'nf_promo_sales', 'food_promo_sales', 'promo_visits_q1', 'promo_visits_q2', 'promo_visits_th', 'promo_visits_lh', 'promo_visits_1y', 'nf_sales_1y', 'nf_sales_q1', 'nf_sales_q2', 'nf_sales_th', 'nf_sales_lh', 'nf_visits_q1', 'nf_visits_q2', 'nf_visits_th', 'nf_visits_lh', 'food_sales_1y', 'food_sales_th', 'food_sales_lh', 'food_visits_1y', 'food_visits_q1', 'food_visits_q2', 'pieces', 'food_colli', 'food_pieces', 'colli_1y', 'colli_q1', 'home_store_visits_q1', 'home_store_visits_th', 'home_store_visits_lh', 'visits_q1', 'visits_q2', 'visits_q3', 'visits_q4', 'visits_1y', 'visits_th', 'visits_lh', 'sales_1y', 'sales_q1', 'sales_q2', 'sales_q3', 'sales_q4', 'sales_th', 'sales_lh', 'ret_visits_q1', 'ret_visits_q2', 'ret_visits_th', 'ret_visits_lh', 'ret_sales_q1', 'ret_sales_q2', 'ret_sales_th', 'ret_sales_lh', 'ret_sales_1y', 'prediction_week']\n",
    "churn_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all = ['timezone_cd', 'tenure_date_created', 'tenure_visit', 'branch', 'abc_cd', 'abc_detailed_cd', 'avg_no_main_cat_1y', 'avg_no_main_cat_q1', 'avg_no_main_cat_q2', 'avg_no_main_cat_th', 'avg_no_main_cat_lh', 'avg_articles_6_6', 'avg_articles_q1_q2', 'churn_flag', 'growth_flag', 'decline_flag', 'ret_visits_per_chg_q1_q2', 'ret_sales_per_chg_q1_q2', 'visit_gap_ratio_th', 'visit_gap_ratio_1y', 'visit_gap_ratio_per_chg_6_6', 'avg_days_between_visits', 'home_st_visits_per_q1', 'home_st_visits_per_6_6', 'basket_spend', 'basket_spend_per_chg_6_6', 'basket_spend_per_chg_q1_q2', 'f_sales_per_chg_6_6', 'nf_visits_per_chg_6_6', 'nf_sales_per_chg_6_6', 'p_visits_per_chg_6_6', 'p_sales_per_chg_6_6', 'ret_visits_per_chg_6_6', 'ret_sales_per_chg_6_6', 'f_visits_per_chg_q1_q2', 'nf_visits_per_chg_q1_q2', 'nf_sales_per_chg_q1_q2', 'p_visits_per_chg_q1_q2', 'p_sales_per_chg_q1_q2', 'consistency_mnth_cd', 'consistency_qtr_cd', 'distinct_weeks_bought', 'expect_visit_flag', 'expect_visit_flag2', 'promo_sales_per', 'margin_per', 'coupon_disc_per', 'food_visits_per', 'food_sales_per', 'food_promo_per', 'nf_promo_per', 'food_colli_per', 'food_pieces_per', 'sales_last_model_period_per', 'visits_last_model_period_per', 'distinct_stores', 'recency', 'coupon_disc', 'margin_1y', 'home_visits_q1', 'home_visits_lh', 'home_visits_th', 'visit_gap_th', 'visit_gap_lh', 'visit_gap_1y', 'promo_sales_1y', 'promo_sales_q1', 'promo_sales_q2', 'promo_sales_th', 'promo_sales_lh', 'nf_promo_sales', 'food_promo_sales', 'promo_visits_q1', 'promo_visits_q2', 'promo_visits_th', 'promo_visits_lh', 'promo_visits_1y', 'nf_sales_1y', 'nf_sales_q1', 'nf_sales_q2', 'nf_sales_th', 'nf_sales_lh', 'nf_visits_q1', 'nf_visits_q2', 'nf_visits_th', 'nf_visits_lh', 'food_sales_1y', 'food_sales_th', 'food_sales_lh', 'food_visits_1y', 'food_visits_q1', 'food_visits_q2', 'pieces', 'food_colli', 'food_pieces', 'colli_1y', 'colli_q1', 'home_store_visits_q1', 'home_store_visits_th', 'home_store_visits_lh', 'visits_q1', 'visits_q2', 'visits_q3', 'visits_q4', 'visits_1y', 'visits_th', 'visits_lh', 'sales_1y', 'sales_q1', 'sales_q2', 'sales_q3', 'sales_q4', 'sales_th', 'sales_lh', 'ret_visits_q1', 'ret_visits_q2', 'ret_visits_th', 'ret_visits_lh', 'ret_sales_q1', 'ret_sales_q2', 'ret_sales_th', 'ret_sales_lh', 'ret_sales_1y', 'prediction_week']\n",
    "used_metro_model = ['margin_per', 'prediction_week', 'basket_spend', 'food_promo_per', 'promo_sales_per', 'recency', 'avg_no_main_cat_1y', 'nf_promo_per', 'visit_gap_th', 'avg_articles_6_6', 'nf_sales_1y', 'avg_no_main_cat_th', 'food_pieces_per', 'avg_no_main_cat_q1', 'visit_gap_ratio_per_chg_6_6', 'avg_articles_q1_q2', 'basket_spend_per_chg_q1_q2', 'food_sales_per', 'visit_gap_1y', 'basket_spend_per_chg_6_6', 'nf_sales_q1', 'nf_promo_sales', 'food_colli_per', 'tenure_visit', 'nf_sales_per_chg_6_6', 'ret_sales_1y', 'nf_sales_th', 'sales_q1', 'colli_q1', 'visit_gap_ratio_th', 'pieces', 'avg_no_main_cat_lh', 'sales_last_model_period_per', 'ret_sales_per_chg_6_6', 'p_sales_per_chg_6_6', 'ret_sales_th', 'nf_sales_lh', 'promo_sales_q1', 'ret_sales_q1', 'avg_no_main_cat_q2', 'p_sales_per_chg_q1_q2', 'nf_sales_per_chg_q1_q2', 'promo_sales_1y', 'f_sales_per_chg_6_6', 'margin_1y', 'ret_sales_lh', 'food_pieces', 'visit_gap_lh', 'f_visits_per_chg_q1_q2', 'visits_last_model_period_per', 'food_promo_sales', 'nf_sales_q2', 'nf_visits_per_chg_6_6', 'ret_sales_q2', 'visit_gap_ratio_1y', 'promo_sales_th', 'promo_sales_lh', 'promo_sales_q2', 'home_st_visits_per_6_6', 'p_visits_per_chg_6_6', 'p_visits_per_chg_q1_q2', 'avg_days_between_visits', 'colli_1y', 'ret_visits_per_chg_6_6', 'food_colli', 'sales_1y', 'sales_q2', 'nf_visits_per_chg_q1_q2', 'sales_q3', 'distinct_weeks_bought', 'ret_sales_per_chg_q1_q2', 'sales_q4', 'nf_visits_lh', 'abc_detailed_cd', 'food_sales_1y', 'food_sales_th', 'promo_visits_1y', 'home_visits_lh', 'home_visits_th', 'sales_lh', 'sales_th', 'visits_q3', 'ret_visits_lh', 'food_sales_lh', 'timezone_cd', 'visits_1y', 'food_visits_1y', 'nf_visits_th', 'promo_visits_lh', 'promo_visits_th', 'ret_visits_per_chg_q1_q2', 'home_visits_q1', 'visits_q4', 'visits_lh', 'nf_visits_q1', 'ret_visits_th', 'home_st_visits_per_q1', 'promo_visits_q1', 'visits_q1', 'branch', 'promo_visits_q2', 'nf_visits_q2', 'food_visits_q1', 'home_store_visits_lh', 'visits_th', 'visits_q2', 'food_visits_q2', 'home_store_visits_th', 'distinct_stores', 'ret_visits_q2', 'ret_visits_q1', 'home_store_visits_q1', 'consistency_mnth_cd', 'abc_cd', 'expect_visit_flag', 'expect_visit_flag2', 'consistency_qtr_cd']\n",
    "for i in range(len(all)):\n",
    "  if all[i] not in used_metro_model:\n",
    "    print(all[i])\n",
    "print(len(all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "churn_dropped = churn_normalized\n",
    "churn_dropped = churn_normalized.drop(['tenure_date_created', 'growth_flag', 'decline_flag', 'coupon_disc_per', 'food_visits_per', 'coupon_disc'], axis = 1)\n",
    "churn_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shuffled = churn_dropped.sample(frac=1)\n",
    "trainsize = int(len(shuffled['prediction_week']) * 0.75)\n",
    "validsize = int(len(shuffled['prediction_week']) * 0.25)\n",
    "\n",
    "df_train = shuffled.iloc[:trainsize, :]\n",
    "df_valid = shuffled.iloc[trainsize:(trainsize+validsize), :]\n",
    "df_test = df_valid\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_csv(df, filename):\n",
    "  outdf = df.copy(deep=False)\n",
    "  \n",
    "  # reorder columns so that target is first column\n",
    "  cols = outdf.columns.tolist()\n",
    "  print (cols)  # new order of columns\n",
    "  outdf = outdf[cols]\n",
    "  outdf.to_csv(filename, header=False, index_label=False, index=False)\n",
    "  \n",
    "  print outdf.shape\n",
    "\n",
    "to_csv(df_train, 'churn-train.csv')\n",
    "to_csv(df_valid, 'churn-valid.csv')\n",
    "to_csv(df_test, 'churn-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timezone_cd</th>\n",
       "      <th>tenure_visit</th>\n",
       "      <th>branch</th>\n",
       "      <th>abc_cd</th>\n",
       "      <th>abc_detailed_cd</th>\n",
       "      <th>avg_no_main_cat_1y</th>\n",
       "      <th>avg_no_main_cat_q1</th>\n",
       "      <th>avg_no_main_cat_q2</th>\n",
       "      <th>avg_no_main_cat_th</th>\n",
       "      <th>avg_no_main_cat_lh</th>\n",
       "      <th>...</th>\n",
       "      <th>ret_visits_q1</th>\n",
       "      <th>ret_visits_q2</th>\n",
       "      <th>ret_visits_th</th>\n",
       "      <th>ret_visits_lh</th>\n",
       "      <th>ret_sales_q1</th>\n",
       "      <th>ret_sales_q2</th>\n",
       "      <th>ret_sales_th</th>\n",
       "      <th>ret_sales_lh</th>\n",
       "      <th>ret_sales_1y</th>\n",
       "      <th>prediction_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "      <td>121918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.224608</td>\n",
       "      <td>0.940470</td>\n",
       "      <td>0.269964</td>\n",
       "      <td>0.816007</td>\n",
       "      <td>0.748238</td>\n",
       "      <td>0.256314</td>\n",
       "      <td>0.205536</td>\n",
       "      <td>0.229002</td>\n",
       "      <td>0.241451</td>\n",
       "      <td>0.200789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037646</td>\n",
       "      <td>0.037861</td>\n",
       "      <td>0.038175</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.492762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.256732</td>\n",
       "      <td>0.152419</td>\n",
       "      <td>0.409685</td>\n",
       "      <td>0.387480</td>\n",
       "      <td>0.238801</td>\n",
       "      <td>0.123812</td>\n",
       "      <td>0.106585</td>\n",
       "      <td>0.116534</td>\n",
       "      <td>0.119880</td>\n",
       "      <td>0.103239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.047743</td>\n",
       "      <td>0.045359</td>\n",
       "      <td>0.045786</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.292748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.169130</td>\n",
       "      <td>0.131455</td>\n",
       "      <td>0.151219</td>\n",
       "      <td>0.157355</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.241715</td>\n",
       "      <td>0.192488</td>\n",
       "      <td>0.217164</td>\n",
       "      <td>0.227098</td>\n",
       "      <td>0.191605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.480769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.997253</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327485</td>\n",
       "      <td>0.266823</td>\n",
       "      <td>0.296020</td>\n",
       "      <td>0.310606</td>\n",
       "      <td>0.260488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252038</td>\n",
       "      <td>0.272004</td>\n",
       "      <td>0.216108</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.230837</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timezone_cd   tenure_visit         branch         abc_cd  \\\n",
       "count  121918.000000  121918.000000  121918.000000  121918.000000   \n",
       "mean        0.224608       0.940470       0.269964       0.816007   \n",
       "std         0.256732       0.152419       0.409685       0.387480   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.972527       0.000000       1.000000   \n",
       "50%         0.250000       0.989011       0.000000       1.000000   \n",
       "75%         0.375000       0.997253       0.500000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       abc_detailed_cd  avg_no_main_cat_1y  avg_no_main_cat_q1  \\\n",
       "count    121918.000000       121918.000000       121918.000000   \n",
       "mean          0.748238            0.256314            0.205536   \n",
       "std           0.238801            0.123812            0.106585   \n",
       "min           0.000000            0.000000            0.000000   \n",
       "25%           0.571429            0.169130            0.131455   \n",
       "50%           0.714286            0.241715            0.192488   \n",
       "75%           1.000000            0.327485            0.266823   \n",
       "max           1.000000            0.968421            0.943662   \n",
       "\n",
       "       avg_no_main_cat_q2  avg_no_main_cat_th  avg_no_main_cat_lh  \\\n",
       "count       121918.000000       121918.000000       121918.000000   \n",
       "mean             0.229002            0.241451            0.200789   \n",
       "std              0.116534            0.119880            0.103239   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.151219            0.157355            0.133333   \n",
       "50%              0.217164            0.227098            0.191605   \n",
       "75%              0.296020            0.310606            0.260488   \n",
       "max              0.985075            0.966942            0.804444   \n",
       "\n",
       "            ...         ret_visits_q1  ret_visits_q2  ret_visits_th  \\\n",
       "count       ...         121918.000000  121918.000000  121918.000000   \n",
       "mean        ...              0.037646       0.037861       0.038175   \n",
       "std         ...              0.047382       0.047743       0.045359   \n",
       "min         ...              0.000000       0.000000       0.000000   \n",
       "25%         ...              0.010989       0.011111       0.011173   \n",
       "50%         ...              0.021978       0.022222       0.022346   \n",
       "75%         ...              0.054945       0.055556       0.050279   \n",
       "max         ...              0.989011       1.000000       0.994413   \n",
       "\n",
       "       ret_visits_lh   ret_sales_q1   ret_sales_q2   ret_sales_th  \\\n",
       "count  121918.000000  121918.000000  121918.000000  121918.000000   \n",
       "mean        0.037769       0.000454       0.000551       0.000498   \n",
       "std         0.045786       0.004240       0.005299       0.004584   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.011364       0.000003       0.000003       0.000015   \n",
       "50%         0.022727       0.000051       0.000059       0.000089   \n",
       "75%         0.051136       0.000244       0.000287       0.000266   \n",
       "max         1.000000       0.252038       0.272004       0.216108   \n",
       "\n",
       "        ret_sales_lh   ret_sales_1y  prediction_week  \n",
       "count  121918.000000  121918.000000    121918.000000  \n",
       "mean        0.000414       0.000474         0.492762  \n",
       "std         0.004327       0.004560         0.292748  \n",
       "min         0.000000       0.000000         0.000000  \n",
       "25%         0.000008       0.000027         0.250000  \n",
       "50%         0.000055       0.000090         0.480769  \n",
       "75%         0.000194       0.000241         0.730769  \n",
       "max         0.236924       0.230837         1.000000  \n",
       "\n",
       "[8 rows x 118 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"churn-test.csv\"\n",
    "\n",
    "names = ['timezone_cd', 'tenure_visit', 'branch', 'abc_cd', 'abc_detailed_cd', 'avg_no_main_cat_1y', 'avg_no_main_cat_q1', 'avg_no_main_cat_q2', 'avg_no_main_cat_th', 'avg_no_main_cat_lh', 'avg_articles_6_6', 'avg_articles_q1_q2', 'churn_flag', 'ret_visits_per_chg_q1_q2', 'ret_sales_per_chg_q1_q2', 'visit_gap_ratio_th', 'visit_gap_ratio_1y', 'visit_gap_ratio_per_chg_6_6', 'avg_days_between_visits', 'home_st_visits_per_q1', 'home_st_visits_per_6_6', 'basket_spend', 'basket_spend_per_chg_6_6', 'basket_spend_per_chg_q1_q2', 'f_sales_per_chg_6_6', 'nf_visits_per_chg_6_6', 'nf_sales_per_chg_6_6', 'p_visits_per_chg_6_6', 'p_sales_per_chg_6_6', 'ret_visits_per_chg_6_6', 'ret_sales_per_chg_6_6', 'f_visits_per_chg_q1_q2', 'nf_visits_per_chg_q1_q2', 'nf_sales_per_chg_q1_q2', 'p_visits_per_chg_q1_q2', 'p_sales_per_chg_q1_q2', 'consistency_mnth_cd', 'consistency_qtr_cd', 'distinct_weeks_bought', 'expect_visit_flag', 'expect_visit_flag2', 'promo_sales_per', 'margin_per', 'food_sales_per', 'food_promo_per', 'nf_promo_per', 'food_colli_per', 'food_pieces_per', 'sales_last_model_period_per', 'visits_last_model_period_per', 'distinct_stores', 'recency', 'margin_1y', 'home_visits_q1', 'home_visits_lh', 'home_visits_th', 'visit_gap_th', 'visit_gap_lh', 'visit_gap_1y', 'promo_sales_1y', 'promo_sales_q1', 'promo_sales_q2', 'promo_sales_th', 'promo_sales_lh', 'nf_promo_sales', 'food_promo_sales', 'promo_visits_q1', 'promo_visits_q2', 'promo_visits_th', 'promo_visits_lh', 'promo_visits_1y', 'nf_sales_1y', 'nf_sales_q1', 'nf_sales_q2', 'nf_sales_th', 'nf_sales_lh', 'nf_visits_q1', 'nf_visits_q2', 'nf_visits_th', 'nf_visits_lh', 'food_sales_1y', 'food_sales_th', 'food_sales_lh', 'food_visits_1y', 'food_visits_q1', 'food_visits_q2', 'pieces', 'food_colli', 'food_pieces', 'colli_1y', 'colli_q1', 'home_store_visits_q1', 'home_store_visits_th', 'home_store_visits_lh', 'visits_q1', 'visits_q2', 'visits_q3', 'visits_q4', 'visits_1y', 'visits_th', 'visits_lh', 'sales_1y', 'sales_q1', 'sales_q2', 'sales_q3', 'sales_q4', 'sales_th', 'sales_lh', 'ret_visits_q1', 'ret_visits_q2', 'ret_visits_th', 'ret_visits_lh', 'ret_sales_q1', 'ret_sales_q2', 'ret_sales_th', 'ret_sales_lh', 'ret_sales_1y', 'prediction_week']  \n",
    "df = pd.read_csv(data, names=names, skiprows=0)  \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc_cd\n",
      "[0. 1.]\n",
      "churn_flag\n",
      "[1. 0.]\n",
      "consistency_mnth_cd\n",
      "[0. 1.]\n",
      "consistency_qtr_cd\n",
      "[1. 0.]\n",
      "expect_visit_flag\n",
      "[1. 0.]\n",
      "expect_visit_flag2\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(names)):\n",
    "  alle = df[names[i]].unique()\n",
    "  if len(alle) < 3:\n",
    "    print(names[i])\n",
    "    print(df[names[i]].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PROJECT = 'metro-bi-dscustomer-internal'\n",
    "BUCKET = 'churn_models'\n",
    "REGION = 'europe-west1'\n",
    "REPO = \"/content/datalab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['REPO'] = REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorizing the Cloud ML Service account service-1057441035629@cloud-ml.google.com.iam.gserviceaccount.com to access files in churn_models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   135    0   135    0     0    133      0 --:--:--  0:00:01 --:--:--   133\r",
      "100   135    0   135    0     0    133      0 --:--:--  0:00:01 --:--:--   133\n",
      "No changes to gs://churn_models/\n",
      "No changes to gs://churn_models/churn_cloud/churn-test.csv\n",
      "No changes to gs://churn_models/churn_cloud/churn-train.csv\n",
      "No changes to gs://churn_models/churn_cloud/churn-valid.csv\n",
      "Updated ACL on gs://churn_models/churn_cloud/churn_trained/checkpoint.20.hdf5\n",
      "Updated ACL on gs://churn_models/churn_cloud/churn_trained/checkpoint.30.hdf5\n",
      "Updated ACL on gs://churn_models/churn_cloud/churn_trained/checkpoint.40.hdf5\n",
      "Updated ACL on gs://churn_models/churn_cloud/churn_trained/\n",
      "Updated ACL on gs://churn_models/churn_cloud/churn_trained/checkpoint.10.hdf5\n",
      "Updated ACL on gs://churn_models/churn_cloud/churn_trained/logs/\n",
      "No changes to gs://churn_models/churn_cloud_hyper/churn-test.csv\n",
      "No changes to gs://churn_models/churn_cloud_hyper/churn-train.csv\n",
      "No changes to gs://churn_models/churn_cloud_hyper/churn-valid.csv\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/\n",
      "Updated ACL on gs://churn_models/churn_cloud/churn_trained/logs/events.out.tfevents.1519923091.cmle-training-17739402783277283780\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/export/\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/churn_model.hdf5\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/export/saved_model.pb\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/logs/\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/export/variables/variables.data-00000-of-00001\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/export/variables/\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/export/variables/variables.index\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/1/logs/events.out.tfevents.1519838056.cmle-training-master-197f3a5d8d-0-10svw\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/export/saved_model.pb\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/churn_model.hdf5\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/export/\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/export/variables/\n",
      "No changes to gs://churn_models/churn_neural_net/churn-test.csv\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/export/variables/variables.data-00000-of-00001\n",
      "No changes to gs://churn_models/churn_neural_net/churn-valid.csv\n",
      "No changes to gs://churn_models/churn_neural_net/churn-train.csv\n",
      "No changes to gs://churn_models/churn_neural_net/churn_trained/\n",
      "No changes to gs://churn_models/churn_neural_net/churn_trained/logs/\n",
      "No changes to gs://churn_models/churn_neural_net/churn_trained/checkpoint.45.hdf5\n",
      "No changes to gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519983037.b3812cb3e1c2\n",
      "No changes to gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519983079.b3812cb3e1c2\n",
      "No changes to gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519983225.b3812cb3e1c2\n",
      "No changes to gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519983281.b3812cb3e1c2\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/logs/\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/logs/events.out.tfevents.1519838359.cmle-training-master-7f637b239a-0-r27gm\n",
      "Updated ACL on gs://churn_models/churn_cloud_hyper/churn_trained/2/export/variables/variables.index\n",
      "No changes to gs://churn_models/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print response['serviceAccount']\")\n",
    "\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn_models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://churn_models/churn_neural_net/churn-test.csv#1519983536986084...\n",
      "Removing gs://churn_models/churn_neural_net/churn-train.csv#1519983551627384...\n",
      "Removing gs://churn_models/churn_neural_net/churn-valid.csv#1519983537158201...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/#1519983569391218...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/checkpoint.45.hdf5#1519988655347702...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/checkpoint.50.hdf5#1519988670957995...\n",
      "/ [1 objects]                                                                   \r",
      "/ [2/42 objects]   4% Done                                                      \r",
      "/ [3/42 objects]   7% Done                                                      \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/checkpoint.60.hdf5#1519988685931312...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/checkpoint.70.hdf5#1519988702142191...\n",
      "/ [4/42 objects]   9% Done                                                      \r",
      "/ [5/42 objects]  11% Done                                                      \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/checkpoint.80.hdf5#1519988719256022...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/checkpoint.90.hdf5#1519988735603434...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/checkpoint.95.hdf5#1519989045840871...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/churn_model.hdf5#1519989060076483...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/export/#1519988550354434...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/export/saved_model.pb#1519988555449963...\n",
      "/ [6/42 objects]  14% Done                                                      \r",
      "/ [7/42 objects]  16% Done                                                      \r",
      "/ [8/42 objects]  19% Done                                                      \r",
      "/ [9/42 objects]  21% Done                                                      \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/export/variables/#1519988553831399...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/export/variables/variables.data-00000-of-00001#1519988554295741...\n",
      "/ [10/42 objects]  23% Done                                                     \r",
      "/ [11/42 objects]  26% Done                                                     \r",
      "/ [12/42 objects]  28% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/export/variables/variables.index#1519988554690356...\n",
      "/ [13/42 objects]  30% Done                                                     \r",
      "/ [14/42 objects]  33% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/#1519983569670335...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519983569.b3812cb3e1c2#1519983789244285...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519984073.b3812cb3e1c2#1519984297754386...\n",
      "/ [15/42 objects]  35% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519984462.b3812cb3e1c2#1519984697988700...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519984840.b3812cb3e1c2#1519985080395022...\n",
      "/ [16/42 objects]  38% Done                                                     \r",
      "/ [17/42 objects]  40% Done                                                     \r",
      "/ [18/42 objects]  42% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519985168.b3812cb3e1c2#1519985173722797...\n",
      "/ [19/42 objects]  45% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519985696.b3812cb3e1c2#1519985701259015...\n",
      "/ [20/42 objects]  47% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519986634.b3812cb3e1c2#1519986844862557...\n",
      "/ [21/42 objects]  50% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519986944.b3812cb3e1c2#1519986948614177...\n",
      "/ [22/42 objects]  52% Done                                                     \r",
      "/ [23/42 objects]  54% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987047.b3812cb3e1c2#1519987048372043...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987108.b3812cb3e1c2#1519987108762533...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987125.b3812cb3e1c2#1519987125708761...\n",
      "/ [24/42 objects]  57% Done                                                     \r",
      "/ [25/42 objects]  59% Done                                                     \r",
      "/ [26/42 objects]  61% Done                                                     \r",
      "/ [27/42 objects]  64% Done                                                     \r",
      "/ [28/42 objects]  66% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987138.b3812cb3e1c2#1519987139726722...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987193.b3812cb3e1c2#1519987194373805...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987177.b3812cb3e1c2#1519987178710495...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987204.b3812cb3e1c2#1519987206061776...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987222.b3812cb3e1c2#1519987224168901...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987335.b3812cb3e1c2#1519987336608585...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987421.b3812cb3e1c2#1519987423160758...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519987436.b3812cb3e1c2#1519987437995771...\n",
      "/ [29/42 objects]  69% Done                                                     \r",
      "/ [30/42 objects]  71% Done                                                     \r",
      "/ [31/42 objects]  73% Done                                                     \r",
      "/ [32/42 objects]  76% Done                                                     \r",
      "/ [33/42 objects]  78% Done                                                     \r",
      "/ [34/42 objects]  80% Done                                                     \r",
      "/ [35/42 objects]  83% Done                                                     \r",
      "/ [36/42 objects]  85% Done                                                     \r",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519988020.b3812cb3e1c2#1519988023388003...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519988543.b3812cb3e1c2#1519988549270259...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519988081.b3812cb3e1c2#1519988083006182...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519988593.b3812cb3e1c2#1519988740614524...\n",
      "Removing gs://churn_models/churn_neural_net/churn_trained/logs/events.out.tfevents.1519988827.b3812cb3e1c2#1519989059767542...\n",
      "/ [37/42 objects]  88% Done                                                     \r",
      "/ [38/42 objects]  90% Done                                                     \r",
      "/ [39/42 objects]  92% Done                                                     \r",
      "/ [40/42 objects]  95% Done                                                     \r",
      "/ [41/42 objects]  97% Done                                                     \r",
      "/ [42/42 objects] 100% Done                                                     \r\n",
      "Operation completed over 42 objects.                                             \n",
      "Copying file:///content/datalab/churn-test.csv [Content-Type=text/csv]...\n",
      "Copying file:///content/datalab/churn-train.csv [Content-Type=text/csv]...\n",
      "/ [0 files][    0.0 B/248.8 MiB]                                                \r",
      "/ [0/3 files][    0.0 B/  1.2 GiB]   0% Done                                    \r",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file:///content/datalab/churn-valid.csv [Content-Type=text/csv]...\n",
      "/ [0/3 files][    0.0 B/  1.2 GiB]   0% Done                                    \r",
      "-\r",
      "- [0/3 files][ 49.0 MiB/  1.2 GiB]   3% Done                                    \r",
      "\\\r",
      "|\r",
      "| [0/3 files][112.9 MiB/  1.2 GiB]   9% Done                                    \r",
      "/\r",
      "/ [0/3 files][174.3 MiB/  1.2 GiB]  14% Done                                    \r",
      "-\r",
      "\\\r",
      "\\ [0/3 files][232.8 MiB/  1.2 GiB]  18% Done                                    \r",
      "|\r",
      "/\r",
      "/ [0/3 files][293.9 MiB/  1.2 GiB]  23% Done                                    \r",
      "-\r",
      "- [0/3 files][354.8 MiB/  1.2 GiB]  28% Done                                    \r",
      "\\\r",
      "|\r",
      "| [0/3 files][416.6 MiB/  1.2 GiB]  33% Done                                    \r",
      "/\r",
      "-\r",
      "- [0/3 files][479.0 MiB/  1.2 GiB]  38% Done                                    \r",
      "\\\r",
      "\\ [0/3 files][541.9 MiB/  1.2 GiB]  43% Done                                    \r",
      "|\r",
      "/\r",
      "/ [0/3 files][601.5 MiB/  1.2 GiB]  48% Done                                    \r",
      "-\r",
      "\\\r",
      "\\ [0/3 files][659.2 MiB/  1.2 GiB]  52% Done  60.8 MiB/s ETA 00:00:10           \r",
      "|\r",
      "| [0/3 files][721.4 MiB/  1.2 GiB]  57% Done  60.7 MiB/s ETA 00:00:09           \r",
      "/\r",
      "/ [1/3 files][757.2 MiB/  1.2 GiB]  60% Done  60.5 MiB/s ETA 00:00:08           \r",
      "-\r",
      "- [2/3 files][787.6 MiB/  1.2 GiB]  63% Done  59.1 MiB/s ETA 00:00:08           \r",
      "\\\r",
      "|\r",
      "| [2/3 files][820.1 MiB/  1.2 GiB]  65% Done  52.8 MiB/s ETA 00:00:08           \r",
      "/\r",
      "-\r",
      "- [2/3 files][854.4 MiB/  1.2 GiB]  68% Done  48.1 MiB/s ETA 00:00:08           \r",
      "\\\r",
      "\\ [2/3 files][895.7 MiB/  1.2 GiB]  72% Done  44.4 MiB/s ETA 00:00:08           \r",
      "|\r",
      "/\r",
      "/ [2/3 files][937.2 MiB/  1.2 GiB]  75% Done  40.5 MiB/s ETA 00:00:08           \r",
      "-\r",
      "\\\r",
      "\\ [2/3 files][978.4 MiB/  1.2 GiB]  78% Done  37.8 MiB/s ETA 00:00:07           \r",
      "|\r",
      "| [2/3 files][ 1021 MiB/  1.2 GiB]  82% Done  40.1 MiB/s ETA 00:00:06           \r",
      "/\r",
      "-\r",
      "- [2/3 files][  1.0 GiB/  1.2 GiB]  85% Done  41.7 MiB/s ETA 00:00:04           \r",
      "\\\r",
      "|\r",
      "| [2/3 files][  1.1 GiB/  1.2 GiB]  89% Done  42.2 MiB/s ETA 00:00:03           \r",
      "/\r",
      "/ [2/3 files][  1.1 GiB/  1.2 GiB]  92% Done  42.4 MiB/s ETA 00:00:02           \r",
      "-\r",
      "\\\r",
      "\\ [2/3 files][  1.2 GiB/  1.2 GiB]  95% Done  42.7 MiB/s ETA 00:00:01           \r",
      "|\r",
      "/\r",
      "/ [2/3 files][  1.2 GiB/  1.2 GiB]  99% Done  42.6 MiB/s ETA 00:00:00           \r",
      "/ [3/3 files][  1.2 GiB/  1.2 GiB] 100% Done  41.4 MiB/s ETA 00:00:00           \r\n",
      "Operation completed over 3 objects/1.2 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/churn_neural_net/\n",
    "gsutil -m cp ${REPO}/*.csv gs://${BUCKET}/churn_neural_net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 2:05 - loss: 0.5751 - acc: 0.9531\n",
      " 14/100 [===>..........................] - ETA: 8s - loss: 0.2147 - acc: 0.9531  \n",
      " 28/100 [=======>......................] - ETA: 3s - loss: 0.1795 - acc: 0.9526\n",
      " 41/100 [===========>..................] - ETA: 2s - loss: 0.1679 - acc: 0.9516\n",
      " 54/100 [===============>..............] - ETA: 1s - loss: 0.1523 - acc: 0.9523\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.1382 - acc: 0.9563\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.1328 - acc: 0.9583\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.1310 - acc: 0.9574\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1288 - acc: 0.9573\n",
      "Epoch 2/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1157 - acc: 0.9375\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0946 - acc: 0.9688\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0838 - acc: 0.9698\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.0950 - acc: 0.9646\n",
      " 53/100 [==============>...............] - ETA: 0s - loss: 0.0950 - acc: 0.9646\n",
      " 58/100 [================>.............] - ETA: 0s - loss: 0.0927 - acc: 0.9661\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.0913 - acc: 0.9674\n",
      " 85/100 [========================>.....] - ETA: 0s - loss: 0.0939 - acc: 0.9660\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9654\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.0943 - acc: 0.9656\n",
      "Epoch 3/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1324 - acc: 0.9531\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.0995 - acc: 0.9676\n",
      " 28/100 [=======>......................] - ETA: 0s - loss: 0.1039 - acc: 0.9632\n",
      " 42/100 [===========>..................] - ETA: 0s - loss: 0.1075 - acc: 0.9602\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.1090 - acc: 0.9607\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1059 - acc: 0.9611\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.1063 - acc: 0.9604\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.1049 - acc: 0.9613\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1049 - acc: 0.9613\n",
      "Epoch 4/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0549 - acc: 0.9688\n",
      "  9/100 [=>............................] - ETA: 0s - loss: 0.0991 - acc: 0.9635\n",
      " 15/100 [===>..........................] - ETA: 4s - loss: 0.0962 - acc: 0.9635\n",
      " 29/100 [=======>......................] - ETA: 2s - loss: 0.0886 - acc: 0.9704\n",
      " 43/100 [===========>..................] - ETA: 1s - loss: 0.0903 - acc: 0.9709\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.0935 - acc: 0.9699\n",
      " 64/100 [==================>...........] - ETA: 0s - loss: 0.0966 - acc: 0.9678\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.0917 - acc: 0.9685\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.0956 - acc: 0.9669\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0967 - acc: 0.9669\n",
      "Epoch 5/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0979 - acc: 0.9688\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0909 - acc: 0.9698\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0943 - acc: 0.9666\n",
      " 43/100 [===========>..................] - ETA: 0s - loss: 0.1031 - acc: 0.9629\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.1006 - acc: 0.9638\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1014 - acc: 0.9631\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.1009 - acc: 0.9635\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.0985 - acc: 0.9637\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9632\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0990 - acc: 0.9633\n",
      "Epoch 6/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1803 - acc: 0.9375\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.1309 - acc: 0.9565\n",
      " 28/100 [=======>......................] - ETA: 0s - loss: 0.1206 - acc: 0.9604\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.1166 - acc: 0.9604\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.1093 - acc: 0.9622\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1066 - acc: 0.9617\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.1073 - acc: 0.9623\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.1050 - acc: 0.9635\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1056 - acc: 0.9634\n",
      "Epoch 7/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0502 - acc: 0.9844\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.0966 - acc: 0.9632\n",
      " 24/100 [======>.......................] - ETA: 0s - loss: 0.0995 - acc: 0.9635\n",
      " 29/100 [=======>......................] - ETA: 2s - loss: 0.0936 - acc: 0.9677\n",
      " 43/100 [===========>..................] - ETA: 1s - loss: 0.0954 - acc: 0.9658\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.0942 - acc: 0.9688\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.0917 - acc: 0.9685\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0941 - acc: 0.9674\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0935 - acc: 0.9672\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0947 - acc: 0.9666\n",
      "Epoch 8/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0261 - acc: 1.0000\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.0917 - acc: 0.9632\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.0915 - acc: 0.9682\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.0901 - acc: 0.9668\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.0896 - acc: 0.9670\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.0869 - acc: 0.9662\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.0884 - acc: 0.9666\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.0893 - acc: 0.9664\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9665\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0890 - acc: 0.9662\n",
      "Epoch 9/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1596 - acc: 0.9531\n",
      " 13/100 [==>...........................] - ETA: 0s - loss: 0.1079 - acc: 0.9627\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.0907 - acc: 0.9694\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.0924 - acc: 0.9691\n",
      " 51/100 [==============>...............] - ETA: 0s - loss: 0.1016 - acc: 0.9642\n",
      " 65/100 [==================>...........] - ETA: 0s - loss: 0.0983 - acc: 0.9656\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.0966 - acc: 0.9655\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0983 - acc: 0.9641\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0959 - acc: 0.9645\n",
      "Epoch 10/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.2196 - acc: 0.9062\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.1353 - acc: 0.9509\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1229 - acc: 0.9572\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.1084 - acc: 0.9595\n",
      " 43/100 [===========>..................] - ETA: 1s - loss: 0.1078 - acc: 0.9604\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.1097 - acc: 0.9586\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1100 - acc: 0.9588\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.1080 - acc: 0.9602\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.1047 - acc: 0.9604\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1045 - acc: 0.9602\n",
      "Epoch 11/100\n",
      "\n",
      "Evaluation epoch[10] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 16:17 - loss: 0.0340 - acc: 1.0000\n",
      " 14/100 [===>..........................] - ETA: 1:00 - loss: 0.0836 - acc: 0.9777 \n",
      " 27/100 [=======>......................] - ETA: 26s - loss: 0.0836 - acc: 0.9734 \n",
      " 39/100 [==========>...................] - ETA: 15s - loss: 0.0869 - acc: 0.9716\n",
      " 52/100 [==============>...............] - ETA: 9s - loss: 0.0853 - acc: 0.9709 \n",
      " 64/100 [==================>...........] - ETA: 5s - loss: 0.0868 - acc: 0.9695\n",
      " 76/100 [=====================>........] - ETA: 3s - loss: 0.0893 - acc: 0.9671\n",
      " 88/100 [=========================>....] - ETA: 1s - loss: 0.0927 - acc: 0.9664\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.0945 - acc: 0.9665\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0962 - acc: 0.9652\n",
      "Epoch 12/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1120 - acc: 0.9531\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.0839 - acc: 0.9710\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.0936 - acc: 0.9651\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.0947 - acc: 0.9631\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0945 - acc: 0.9639\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.0941 - acc: 0.9647\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0957 - acc: 0.9639\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0955 - acc: 0.9644\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0960 - acc: 0.9642\n",
      "Epoch 13/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0812 - acc: 0.9844\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0963 - acc: 0.9648\n",
      " 24/100 [======>.......................] - ETA: 0s - loss: 0.0961 - acc: 0.9661\n",
      " 35/100 [=========>....................] - ETA: 0s - loss: 0.1057 - acc: 0.9603\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.1025 - acc: 0.9616\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.0945 - acc: 0.9655\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.0937 - acc: 0.9647\n",
      " 84/100 [========================>.....] - ETA: 0s - loss: 0.0905 - acc: 0.9661\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9654\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0917 - acc: 0.9656\n",
      "Epoch 14/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1120 - acc: 0.9531\n",
      " 16/100 [===>..........................] - ETA: 0s - loss: 0.0998 - acc: 0.9580\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0955 - acc: 0.9617\n",
      " 43/100 [===========>..................] - ETA: 0s - loss: 0.1100 - acc: 0.9571\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.1091 - acc: 0.9572\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.1046 - acc: 0.9583\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.1039 - acc: 0.9580\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.1022 - acc: 0.9595\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1033 - acc: 0.9597\n",
      "Epoch 15/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0724 - acc: 0.9688\n",
      " 13/100 [==>...........................] - ETA: 0s - loss: 0.0884 - acc: 0.9712\n",
      " 14/100 [===>..........................] - ETA: 5s - loss: 0.0892 - acc: 0.9710\n",
      " 27/100 [=======>......................] - ETA: 2s - loss: 0.0923 - acc: 0.9670\n",
      " 40/100 [===========>..................] - ETA: 1s - loss: 0.0913 - acc: 0.9656\n",
      " 51/100 [==============>...............] - ETA: 0s - loss: 0.0925 - acc: 0.9657\n",
      " 64/100 [==================>...........] - ETA: 0s - loss: 0.0940 - acc: 0.9670\n",
      " 77/100 [======================>.......] - ETA: 0s - loss: 0.0952 - acc: 0.9675\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 0.0939 - acc: 0.9672\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0906 - acc: 0.9681\n",
      "Epoch 16/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0494 - acc: 0.9688\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0992 - acc: 0.9552\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1129 - acc: 0.9572\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.1079 - acc: 0.9598\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.1125 - acc: 0.9572\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.1115 - acc: 0.9579\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.1110 - acc: 0.9573\n",
      " 83/100 [=======================>......] - ETA: 0s - loss: 0.1076 - acc: 0.9588\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.1086 - acc: 0.9585\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1075 - acc: 0.9586\n",
      "Epoch 17/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0527 - acc: 0.9688\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.0997 - acc: 0.9609\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.0863 - acc: 0.9676\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.0899 - acc: 0.9699\n",
      " 53/100 [==============>...............] - ETA: 0s - loss: 0.0943 - acc: 0.9679\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.1001 - acc: 0.9643\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.0991 - acc: 0.9637\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0984 - acc: 0.9645\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0973 - acc: 0.9644\n",
      "Epoch 18/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0910 - acc: 0.9531\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.1165 - acc: 0.9604\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.1109 - acc: 0.9621\n",
      " 28/100 [=======>......................] - ETA: 2s - loss: 0.1065 - acc: 0.9643\n",
      " 38/100 [==========>...................] - ETA: 1s - loss: 0.1085 - acc: 0.9626\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.1076 - acc: 0.9621\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.1077 - acc: 0.9621\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.1108 - acc: 0.9611\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.1083 - acc: 0.9615\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1056 - acc: 0.9623\n",
      "Epoch 19/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1673 - acc: 0.9375\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.1023 - acc: 0.9554\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1107 - acc: 0.9560\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.1086 - acc: 0.9581\n",
      " 53/100 [==============>...............] - ETA: 0s - loss: 0.1048 - acc: 0.9599\n",
      " 65/100 [==================>...........] - ETA: 0s - loss: 0.1016 - acc: 0.9613\n",
      " 76/100 [=====================>........] - ETA: 0s - loss: 0.1025 - acc: 0.9603\n",
      " 85/100 [========================>.....] - ETA: 0s - loss: 0.0993 - acc: 0.9608\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9622\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0962 - acc: 0.9627\n",
      "Epoch 20/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0146 - acc: 1.0000\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.1005 - acc: 0.9665\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1068 - acc: 0.9606\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.1012 - acc: 0.9643\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.1041 - acc: 0.9630\n",
      " 65/100 [==================>...........] - ETA: 0s - loss: 0.1058 - acc: 0.9620\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.1030 - acc: 0.9621\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 0.1064 - acc: 0.9608\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1035 - acc: 0.9616\n",
      "Epoch 21/100\n",
      "\n",
      "Evaluation epoch[20] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 15:49 - loss: 0.0528 - acc: 0.9688\n",
      " 14/100 [===>..........................] - ETA: 59s - loss: 0.1038 - acc: 0.9654  \n",
      " 26/100 [======>.......................] - ETA: 27s - loss: 0.0934 - acc: 0.9657\n",
      " 37/100 [==========>...................] - ETA: 16s - loss: 0.0965 - acc: 0.9616\n",
      " 42/100 [===========>..................] - ETA: 14s - loss: 0.0953 - acc: 0.9617\n",
      " 55/100 [===============>..............] - ETA: 8s - loss: 0.0931 - acc: 0.9639 \n",
      " 69/100 [===================>..........] - ETA: 4s - loss: 0.0986 - acc: 0.9611\n",
      " 81/100 [=======================>......] - ETA: 2s - loss: 0.0945 - acc: 0.9630\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.0964 - acc: 0.9617\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.0964 - acc: 0.9620\n",
      "Epoch 22/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1458 - acc: 0.9688\n",
      " 13/100 [==>...........................] - ETA: 0s - loss: 0.1090 - acc: 0.9639\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.0878 - acc: 0.9718\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.0925 - acc: 0.9712\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0942 - acc: 0.9712\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.0931 - acc: 0.9690\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.0882 - acc: 0.9711\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.0906 - acc: 0.9704\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9702\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0901 - acc: 0.9700\n",
      "Epoch 23/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0802 - acc: 0.9531\n",
      " 16/100 [===>..........................] - ETA: 0s - loss: 0.0846 - acc: 0.9678\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0874 - acc: 0.9644\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.0863 - acc: 0.9672\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.0847 - acc: 0.9679\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0900 - acc: 0.9667\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0879 - acc: 0.9678\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0885 - acc: 0.9674\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0884 - acc: 0.9672\n",
      "Epoch 24/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0616 - acc: 0.9688\n",
      " 13/100 [==>...........................] - ETA: 0s - loss: 0.1140 - acc: 0.9579\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1008 - acc: 0.9624\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.0936 - acc: 0.9645\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0918 - acc: 0.9660\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.0942 - acc: 0.9637\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.0934 - acc: 0.9629\n",
      " 85/100 [========================>.....] - ETA: 0s - loss: 0.0906 - acc: 0.9638\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0934 - acc: 0.9630\n",
      "Epoch 25/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0566 - acc: 0.9688\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0850 - acc: 0.9714\n",
      " 25/100 [======>.......................] - ETA: 0s - loss: 0.0919 - acc: 0.9637\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.1061 - acc: 0.9582\n",
      " 51/100 [==============>...............] - ETA: 0s - loss: 0.1063 - acc: 0.9577\n",
      " 65/100 [==================>...........] - ETA: 0s - loss: 0.1027 - acc: 0.9601\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.1004 - acc: 0.9617\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 0.1002 - acc: 0.9620\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0992 - acc: 0.9620\n",
      "Epoch 26/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1536 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.1225 - acc: 0.9673\n",
      " 13/100 [==>...........................] - ETA: 5s - loss: 0.1337 - acc: 0.9615\n",
      " 26/100 [======>.......................] - ETA: 2s - loss: 0.1070 - acc: 0.9663\n",
      " 40/100 [===========>..................] - ETA: 1s - loss: 0.1076 - acc: 0.9648\n",
      " 53/100 [==============>...............] - ETA: 0s - loss: 0.1044 - acc: 0.9661\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.1034 - acc: 0.9643\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.1016 - acc: 0.9647\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.1013 - acc: 0.9645\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1020 - acc: 0.9638\n",
      "Epoch 27/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0950 - acc: 0.9844\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0901 - acc: 0.9656\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0827 - acc: 0.9677\n",
      " 44/100 [============>.................] - ETA: 0s - loss: 0.0879 - acc: 0.9652\n",
      " 59/100 [================>.............] - ETA: 0s - loss: 0.0902 - acc: 0.9656\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0927 - acc: 0.9656\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.0944 - acc: 0.9652\n",
      " 84/100 [========================>.....] - ETA: 0s - loss: 0.0966 - acc: 0.9639\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9649\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.0942 - acc: 0.9647\n",
      "Epoch 28/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0586 - acc: 0.9688\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.0836 - acc: 0.9676\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.0967 - acc: 0.9612\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.0911 - acc: 0.9638\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.0889 - acc: 0.9641\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.0856 - acc: 0.9646\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.0861 - acc: 0.9657\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.0873 - acc: 0.9645\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0869 - acc: 0.9648\n",
      "Epoch 29/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0691 - acc: 0.9844\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0985 - acc: 0.9656\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.0999 - acc: 0.9657\n",
      " 27/100 [=======>......................] - ETA: 2s - loss: 0.0978 - acc: 0.9664\n",
      " 40/100 [===========>..................] - ETA: 1s - loss: 0.1055 - acc: 0.9641\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.1002 - acc: 0.9651\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1007 - acc: 0.9651\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.0980 - acc: 0.9660\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 0.0945 - acc: 0.9669\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0960 - acc: 0.9658\n",
      "Epoch 30/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0847 - acc: 0.9531\n",
      " 16/100 [===>..........................] - ETA: 0s - loss: 0.0976 - acc: 0.9658\n",
      " 31/100 [========>.....................] - ETA: 0s - loss: 0.1052 - acc: 0.9612\n",
      " 45/100 [============>.................] - ETA: 0s - loss: 0.0994 - acc: 0.9642\n",
      " 58/100 [================>.............] - ETA: 0s - loss: 0.0991 - acc: 0.9647\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.0946 - acc: 0.9661\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.0969 - acc: 0.9659\n",
      " 84/100 [========================>.....] - ETA: 0s - loss: 0.0962 - acc: 0.9661\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.0957 - acc: 0.9658\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.0964 - acc: 0.9655\n",
      "Epoch 31/100\n",
      "\n",
      "Evaluation epoch[30] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 16:30 - loss: 0.1284 - acc: 0.9375\n",
      " 15/100 [===>..........................] - ETA: 56s - loss: 0.0881 - acc: 0.9625  \n",
      " 29/100 [=======>......................] - ETA: 24s - loss: 0.0972 - acc: 0.9639\n",
      " 42/100 [===========>..................] - ETA: 14s - loss: 0.0980 - acc: 0.9643\n",
      " 56/100 [===============>..............] - ETA: 8s - loss: 0.0935 - acc: 0.9660 \n",
      " 68/100 [===================>..........] - ETA: 4s - loss: 0.0921 - acc: 0.9662\n",
      " 81/100 [=======================>......] - ETA: 2s - loss: 0.0965 - acc: 0.9635\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 0.0953 - acc: 0.9643\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 0.0956 - acc: 0.9639\n",
      "Epoch 32/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1450 - acc: 0.9219\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0984 - acc: 0.9596\n",
      " 24/100 [======>.......................] - ETA: 0s - loss: 0.0955 - acc: 0.9642\n",
      " 34/100 [=========>....................] - ETA: 0s - loss: 0.0853 - acc: 0.9669\n",
      " 41/100 [===========>..................] - ETA: 1s - loss: 0.0864 - acc: 0.9661\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.0863 - acc: 0.9650\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.0873 - acc: 0.9653\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0907 - acc: 0.9648\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0908 - acc: 0.9656\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0918 - acc: 0.9656\n",
      "Epoch 33/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0471 - acc: 0.9844\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.0907 - acc: 0.9598\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.0984 - acc: 0.9633\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.0909 - acc: 0.9663\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0887 - acc: 0.9684\n",
      " 65/100 [==================>...........] - ETA: 0s - loss: 0.0969 - acc: 0.9644\n",
      " 77/100 [======================>.......] - ETA: 0s - loss: 0.0980 - acc: 0.9641\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 0.0995 - acc: 0.9641\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9629\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1059 - acc: 0.9627\n",
      "Epoch 34/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0359 - acc: 1.0000\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0762 - acc: 0.9656\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.0941 - acc: 0.9603\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.0991 - acc: 0.9609\n",
      " 53/100 [==============>...............] - ETA: 0s - loss: 0.0920 - acc: 0.9640\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.0913 - acc: 0.9635\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.0928 - acc: 0.9660\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0937 - acc: 0.9655\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0963 - acc: 0.9639\n",
      "Epoch 35/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1837 - acc: 0.9531\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.1172 - acc: 0.9587\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.0995 - acc: 0.9641\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.0981 - acc: 0.9653\n",
      " 50/100 [==============>...............] - ETA: 0s - loss: 0.0979 - acc: 0.9666\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.0949 - acc: 0.9676\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.0962 - acc: 0.9663\n",
      " 85/100 [========================>.....] - ETA: 0s - loss: 0.0938 - acc: 0.9669\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9664\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0943 - acc: 0.9666\n",
      "Epoch 36/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1623 - acc: 0.9531\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0889 - acc: 0.9698\n",
      " 28/100 [=======>......................] - ETA: 0s - loss: 0.0975 - acc: 0.9643\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.0952 - acc: 0.9660\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.0992 - acc: 0.9638\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.0996 - acc: 0.9632\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.0959 - acc: 0.9641\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 0.0956 - acc: 0.9641\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0945 - acc: 0.9653\n",
      "Epoch 37/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1079 - acc: 0.9531\n",
      "  8/100 [=>............................] - ETA: 0s - loss: 0.1214 - acc: 0.9648\n",
      " 12/100 [==>...........................] - ETA: 6s - loss: 0.1159 - acc: 0.9661\n",
      " 25/100 [======>.......................] - ETA: 2s - loss: 0.1109 - acc: 0.9613\n",
      " 38/100 [==========>...................] - ETA: 1s - loss: 0.1026 - acc: 0.9638\n",
      " 51/100 [==============>...............] - ETA: 0s - loss: 0.1010 - acc: 0.9642\n",
      " 60/100 [=================>............] - ETA: 0s - loss: 0.1030 - acc: 0.9628\n",
      " 73/100 [====================>.........] - ETA: 0s - loss: 0.1032 - acc: 0.9623\n",
      " 87/100 [=========================>....] - ETA: 0s - loss: 0.1038 - acc: 0.9621\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1017 - acc: 0.9631\n",
      "Epoch 38/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1934 - acc: 0.9219\n",
      " 14/100 [===>..........................] - ETA: 0s - loss: 0.1319 - acc: 0.9565\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.1196 - acc: 0.9609\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.1137 - acc: 0.9618\n",
      " 49/100 [=============>................] - ETA: 0s - loss: 0.1031 - acc: 0.9652\n",
      " 60/100 [=================>............] - ETA: 0s - loss: 0.0971 - acc: 0.9656\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0986 - acc: 0.9644\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.0967 - acc: 0.9640\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.0940 - acc: 0.9647\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0943 - acc: 0.9644\n",
      "Epoch 39/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0595 - acc: 0.9844\n",
      " 13/100 [==>...........................] - ETA: 0s - loss: 0.0893 - acc: 0.9651\n",
      " 26/100 [======>.......................] - ETA: 0s - loss: 0.0964 - acc: 0.9657\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.1013 - acc: 0.9624\n",
      " 49/100 [=============>................] - ETA: 0s - loss: 0.1027 - acc: 0.9633\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.1058 - acc: 0.9630\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1076 - acc: 0.9597\n",
      " 83/100 [=======================>......] - ETA: 0s - loss: 0.1029 - acc: 0.9618\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 0.1005 - acc: 0.9631\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1031 - acc: 0.9619\n",
      "Epoch 40/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0726 - acc: 0.9688\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0896 - acc: 0.9677\n",
      " 24/100 [======>.......................] - ETA: 0s - loss: 0.0850 - acc: 0.9714\n",
      " 26/100 [======>.......................] - ETA: 2s - loss: 0.0849 - acc: 0.9724\n",
      " 40/100 [===========>..................] - ETA: 1s - loss: 0.0933 - acc: 0.9707\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.0897 - acc: 0.9716\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.0930 - acc: 0.9683\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0933 - acc: 0.9689\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0984 - acc: 0.9667\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0980 - acc: 0.9669\n",
      "Epoch 41/100\n",
      "\n",
      "Evaluation epoch[40] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 17:22 - loss: 0.0687 - acc: 0.9688\n",
      " 17/100 [====>.........................] - ETA: 51s - loss: 0.0881 - acc: 0.9623  \n",
      " 32/100 [========>.....................] - ETA: 22s - loss: 0.0952 - acc: 0.9595\n",
      " 47/100 [=============>................] - ETA: 12s - loss: 0.1030 - acc: 0.9594\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.0979 - acc: 0.9620 \n",
      " 70/100 [====================>.........] - ETA: 4s - loss: 0.0943 - acc: 0.9625\n",
      " 81/100 [=======================>......] - ETA: 2s - loss: 0.0948 - acc: 0.9637\n",
      " 83/100 [=======================>......] - ETA: 2s - loss: 0.0942 - acc: 0.9635\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9640\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0943 - acc: 0.9641\n",
      "Epoch 42/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0373 - acc: 0.9844\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.1033 - acc: 0.9677\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.0977 - acc: 0.9641\n",
      " 44/100 [============>.................] - ETA: 0s - loss: 0.0928 - acc: 0.9645\n",
      " 59/100 [================>.............] - ETA: 0s - loss: 0.0960 - acc: 0.9656\n",
      " 74/100 [=====================>........] - ETA: 0s - loss: 0.1003 - acc: 0.9645\n",
      " 87/100 [=========================>....] - ETA: 0s - loss: 0.0978 - acc: 0.9652\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0951 - acc: 0.9664\n",
      "Epoch 43/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0510 - acc: 0.9844\n",
      " 17/100 [====>.........................] - ETA: 0s - loss: 0.0719 - acc: 0.9724\n",
      " 31/100 [========>.....................] - ETA: 0s - loss: 0.0875 - acc: 0.9647\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.0856 - acc: 0.9659\n",
      " 40/100 [===========>..................] - ETA: 1s - loss: 0.0835 - acc: 0.9668\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0887 - acc: 0.9654\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.0954 - acc: 0.9626\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.0945 - acc: 0.9639\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.0974 - acc: 0.9632\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.0969 - acc: 0.9627\n",
      "Epoch 44/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0970 - acc: 0.9375\n",
      " 16/100 [===>..........................] - ETA: 0s - loss: 0.1100 - acc: 0.9521\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.0982 - acc: 0.9594\n",
      " 45/100 [============>.................] - ETA: 0s - loss: 0.0965 - acc: 0.9639\n",
      " 59/100 [================>.............] - ETA: 0s - loss: 0.0978 - acc: 0.9624\n",
      " 74/100 [=====================>........] - ETA: 0s - loss: 0.0924 - acc: 0.9635\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.0934 - acc: 0.9637\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9638\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.0924 - acc: 0.9641\n",
      "Epoch 45/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0887 - acc: 0.9688\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.1205 - acc: 0.9542\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0942 - acc: 0.9628\n",
      " 43/100 [===========>..................] - ETA: 0s - loss: 0.0945 - acc: 0.9629\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.0942 - acc: 0.9654\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.0997 - acc: 0.9629\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.0981 - acc: 0.9632\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9625\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0993 - acc: 0.9620\n",
      "Epoch 46/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1066 - acc: 0.9531\n",
      " 16/100 [===>..........................] - ETA: 0s - loss: 0.0957 - acc: 0.9697\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.1005 - acc: 0.9625\n",
      " 44/100 [============>.................] - ETA: 0s - loss: 0.1015 - acc: 0.9631\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.1025 - acc: 0.9641\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0946 - acc: 0.9660\n",
      " 83/100 [=======================>......] - ETA: 0s - loss: 0.0942 - acc: 0.9663\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.0892 - acc: 0.9681\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0898 - acc: 0.9681\n",
      "Epoch 47/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0476 - acc: 0.9688\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0701 - acc: 0.9753\n",
      " 25/100 [======>.......................] - ETA: 0s - loss: 0.0881 - acc: 0.9694\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.0973 - acc: 0.9663\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0979 - acc: 0.9648\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.0974 - acc: 0.9650\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0958 - acc: 0.9664\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0955 - acc: 0.9661\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0955 - acc: 0.9655\n",
      "Epoch 48/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0306 - acc: 1.0000\n",
      " 11/100 [==>...........................] - ETA: 7s - loss: 0.0778 - acc: 0.9645\n",
      " 25/100 [======>.......................] - ETA: 2s - loss: 0.0981 - acc: 0.9613\n",
      " 40/100 [===========>..................] - ETA: 1s - loss: 0.0943 - acc: 0.9621\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.0991 - acc: 0.9644\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0996 - acc: 0.9647\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.0990 - acc: 0.9647\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.0986 - acc: 0.9648\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0992 - acc: 0.9645\n",
      "Epoch 49/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0903 - acc: 0.9375\n",
      " 15/100 [===>..........................] - ETA: 0s - loss: 0.0981 - acc: 0.9604\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0878 - acc: 0.9655\n",
      " 42/100 [===========>..................] - ETA: 0s - loss: 0.0890 - acc: 0.9669\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.0928 - acc: 0.9657\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.0940 - acc: 0.9642\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0947 - acc: 0.9633\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0937 - acc: 0.9635\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0912 - acc: 0.9648\n",
      "Epoch 50/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0988 - acc: 0.9531\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0965 - acc: 0.9702\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.1039 - acc: 0.9664\n",
      " 31/100 [========>.....................] - ETA: 0s - loss: 0.1143 - acc: 0.9657\n",
      " 43/100 [===========>..................] - ETA: 0s - loss: 0.1155 - acc: 0.9662\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.1177 - acc: 0.9657\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1183 - acc: 0.9644\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.1167 - acc: 0.9633\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.1159 - acc: 0.9640\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1143 - acc: 0.9645\n",
      "Epoch 51/100\n",
      "\n",
      "Evaluation epoch[50] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 24:14 - loss: 0.0440 - acc: 0.9844\n",
      " 11/100 [==>...........................] - ETA: 1:59 - loss: 0.0739 - acc: 0.9730 \n",
      " 19/100 [====>.........................] - ETA: 1:03 - loss: 0.0923 - acc: 0.9688\n",
      " 25/100 [======>.......................] - ETA: 49s - loss: 0.0964 - acc: 0.9688 \n",
      " 35/100 [=========>....................] - ETA: 30s - loss: 0.1039 - acc: 0.9652\n",
      " 44/100 [============>.................] - ETA: 21s - loss: 0.0971 - acc: 0.9666\n",
      " 53/100 [==============>...............] - ETA: 14s - loss: 0.1029 - acc: 0.9637\n",
      " 62/100 [=================>............] - ETA: 10s - loss: 0.1006 - acc: 0.9637\n",
      " 72/100 [====================>.........] - ETA: 6s - loss: 0.1057 - acc: 0.9612 \n",
      " 81/100 [=======================>......] - ETA: 3s - loss: 0.1040 - acc: 0.9610\n",
      " 90/100 [==========================>...] - ETA: 1s - loss: 0.1046 - acc: 0.9616\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 0.1038 - acc: 0.9612\n",
      "Epoch 52/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0542 - acc: 0.9844\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.1064 - acc: 0.9545\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0854 - acc: 0.9656\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0880 - acc: 0.9655\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.0926 - acc: 0.9650\n",
      " 47/100 [=============>................] - ETA: 0s - loss: 0.0943 - acc: 0.9648\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.0939 - acc: 0.9651\n",
      " 65/100 [==================>...........] - ETA: 0s - loss: 0.0970 - acc: 0.9659\n",
      " 74/100 [=====================>........] - ETA: 0s - loss: 0.0928 - acc: 0.9673\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.0962 - acc: 0.9657\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.0957 - acc: 0.9659\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0944 - acc: 0.9657\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.0938 - acc: 0.9659\n",
      "Epoch 53/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1781 - acc: 0.9219\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.1035 - acc: 0.9583\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.1163 - acc: 0.9613\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.1082 - acc: 0.9628\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.1020 - acc: 0.9637\n",
      " 46/100 [============>.................] - ETA: 0s - loss: 0.0982 - acc: 0.9643\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.1011 - acc: 0.9644\n",
      " 63/100 [=================>............] - ETA: 0s - loss: 0.0994 - acc: 0.9650\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.0990 - acc: 0.9654\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0996 - acc: 0.9654\n",
      " 88/100 [=========================>....] - ETA: 0s - loss: 0.1013 - acc: 0.9652\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9655\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0994 - acc: 0.9655\n",
      "Epoch 54/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.3184 - acc: 0.9219\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.1079 - acc: 0.9631\n",
      " 19/100 [====>.........................] - ETA: 0s - loss: 0.1020 - acc: 0.9597\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1072 - acc: 0.9583\n",
      " 34/100 [=========>....................] - ETA: 0s - loss: 0.1031 - acc: 0.9605\n",
      " 39/100 [==========>...................] - ETA: 2s - loss: 0.1044 - acc: 0.9603\n",
      " 49/100 [=============>................] - ETA: 1s - loss: 0.1026 - acc: 0.9608\n",
      " 57/100 [================>.............] - ETA: 1s - loss: 0.1014 - acc: 0.9611\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.1028 - acc: 0.9613\n",
      " 77/100 [======================>.......] - ETA: 0s - loss: 0.1045 - acc: 0.9606\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.1047 - acc: 0.9608\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.1056 - acc: 0.9603\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.1066 - acc: 0.9606\n",
      "Epoch 55/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0520 - acc: 0.9844\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0851 - acc: 0.9759\n",
      " 19/100 [====>.........................] - ETA: 0s - loss: 0.0988 - acc: 0.9679\n",
      " 28/100 [=======>......................] - ETA: 0s - loss: 0.1019 - acc: 0.9682\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.0958 - acc: 0.9700\n",
      " 46/100 [============>.................] - ETA: 0s - loss: 0.0927 - acc: 0.9694\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.0894 - acc: 0.9707\n",
      " 64/100 [==================>...........] - ETA: 0s - loss: 0.0865 - acc: 0.9712\n",
      " 75/100 [=====================>........] - ETA: 0s - loss: 0.0908 - acc: 0.9692\n",
      " 84/100 [========================>.....] - ETA: 0s - loss: 0.0883 - acc: 0.9695\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0894 - acc: 0.9689\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.0879 - acc: 0.9689\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.0893 - acc: 0.9686\n",
      "Epoch 56/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0569 - acc: 0.9531\n",
      " 10/100 [==>...........................] - ETA: 0s - loss: 0.0865 - acc: 0.9656\n",
      " 18/100 [====>.........................] - ETA: 0s - loss: 0.0876 - acc: 0.9644\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.0969 - acc: 0.9647\n",
      " 35/100 [=========>....................] - ETA: 0s - loss: 0.0965 - acc: 0.9647\n",
      " 44/100 [============>.................] - ETA: 0s - loss: 0.0905 - acc: 0.9677\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0900 - acc: 0.9697\n",
      " 62/100 [=================>............] - ETA: 0s - loss: 0.0895 - acc: 0.9682\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.0935 - acc: 0.9672\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.0931 - acc: 0.9668\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0927 - acc: 0.9670\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0936 - acc: 0.9673\n",
      "Epoch 57/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0963 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0708 - acc: 0.9744\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.0889 - acc: 0.9658\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.0924 - acc: 0.9641\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.1012 - acc: 0.9628\n",
      " 46/100 [============>.................] - ETA: 0s - loss: 0.0986 - acc: 0.9637\n",
      " 53/100 [==============>...............] - ETA: 0s - loss: 0.1010 - acc: 0.9634\n",
      " 63/100 [=================>............] - ETA: 0s - loss: 0.1037 - acc: 0.9616\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.1011 - acc: 0.9617\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.1044 - acc: 0.9602\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.1027 - acc: 0.9605\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9609\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.1014 - acc: 0.9614\n",
      "Epoch 58/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0554 - acc: 0.9844\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0922 - acc: 0.9673\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.1041 - acc: 0.9648\n",
      " 28/100 [=======>......................] - ETA: 0s - loss: 0.0939 - acc: 0.9671\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.0922 - acc: 0.9666\n",
      " 43/100 [===========>..................] - ETA: 2s - loss: 0.0923 - acc: 0.9662\n",
      " 51/100 [==============>...............] - ETA: 1s - loss: 0.0955 - acc: 0.9641\n",
      " 60/100 [=================>............] - ETA: 1s - loss: 0.0969 - acc: 0.9643\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0947 - acc: 0.9658\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.1012 - acc: 0.9655\n",
      " 88/100 [=========================>....] - ETA: 0s - loss: 0.1013 - acc: 0.9654\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9659\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0993 - acc: 0.9656\n",
      "Epoch 59/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0756 - acc: 0.9531\n",
      "  8/100 [=>............................] - ETA: 0s - loss: 0.0643 - acc: 0.9805\n",
      " 17/100 [====>.........................] - ETA: 0s - loss: 0.0812 - acc: 0.9733\n",
      " 25/100 [======>.......................] - ETA: 0s - loss: 0.0817 - acc: 0.9719\n",
      " 34/100 [=========>....................] - ETA: 0s - loss: 0.0865 - acc: 0.9683\n",
      " 44/100 [============>.................] - ETA: 0s - loss: 0.0879 - acc: 0.9680\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.0858 - acc: 0.9690\n",
      " 62/100 [=================>............] - ETA: 0s - loss: 0.0837 - acc: 0.9705\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.0820 - acc: 0.9714\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0868 - acc: 0.9689\n",
      " 88/100 [=========================>....] - ETA: 0s - loss: 0.0856 - acc: 0.9689\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.0851 - acc: 0.9689\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0838 - acc: 0.9695\n",
      "Epoch 60/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0931 - acc: 0.9844\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0792 - acc: 0.9744\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0841 - acc: 0.9734\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0877 - acc: 0.9698\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.0922 - acc: 0.9679\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.0874 - acc: 0.9697\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.0915 - acc: 0.9677\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.0936 - acc: 0.9664\n",
      " 76/100 [=====================>........] - ETA: 0s - loss: 0.0933 - acc: 0.9659\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.0943 - acc: 0.9649\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.0969 - acc: 0.9647\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0989 - acc: 0.9645\n",
      "Epoch 61/100\n",
      "\n",
      "Evaluation epoch[60] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 30:10 - loss: 0.0832 - acc: 0.9375\n",
      " 11/100 [==>...........................] - ETA: 2:28 - loss: 0.0769 - acc: 0.9659 \n",
      " 20/100 [=====>........................] - ETA: 1:13 - loss: 0.0860 - acc: 0.9633\n",
      " 30/100 [========>.....................] - ETA: 43s - loss: 0.0890 - acc: 0.9646 \n",
      " 39/100 [==========>...................] - ETA: 28s - loss: 0.0889 - acc: 0.9651\n",
      " 44/100 [============>.................] - ETA: 23s - loss: 0.0870 - acc: 0.9656\n",
      " 51/100 [==============>...............] - ETA: 17s - loss: 0.0890 - acc: 0.9654\n",
      " 57/100 [================>.............] - ETA: 15s - loss: 0.0897 - acc: 0.9655\n",
      " 67/100 [===================>..........] - ETA: 9s - loss: 0.0909 - acc: 0.9655 \n",
      " 77/100 [======================>.......] - ETA: 6s - loss: 0.0869 - acc: 0.9673\n",
      " 86/100 [========================>.....] - ETA: 3s - loss: 0.0895 - acc: 0.9677\n",
      " 95/100 [===========================>..] - ETA: 1s - loss: 0.0895 - acc: 0.9674\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 0.0910 - acc: 0.9667\n",
      "Epoch 62/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1654 - acc: 0.9375\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0831 - acc: 0.9673\n",
      " 19/100 [====>.........................] - ETA: 0s - loss: 0.0761 - acc: 0.9696\n",
      " 28/100 [=======>......................] - ETA: 0s - loss: 0.0823 - acc: 0.9688\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.0939 - acc: 0.9667\n",
      " 49/100 [=============>................] - ETA: 0s - loss: 0.0933 - acc: 0.9684\n",
      " 59/100 [================>.............] - ETA: 0s - loss: 0.0909 - acc: 0.9688\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0916 - acc: 0.9683\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.0937 - acc: 0.9665\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.0936 - acc: 0.9665\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9665\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0937 - acc: 0.9666\n",
      "Epoch 63/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0683 - acc: 0.9688\n",
      "  9/100 [=>............................] - ETA: 0s - loss: 0.1157 - acc: 0.9531\n",
      " 14/100 [===>..........................] - ETA: 10s - loss: 0.1047 - acc: 0.9576\n",
      " 21/100 [=====>........................] - ETA: 6s - loss: 0.1012 - acc: 0.9598 \n",
      " 28/100 [=======>......................] - ETA: 4s - loss: 0.0966 - acc: 0.9609\n",
      " 37/100 [==========>...................] - ETA: 3s - loss: 0.0921 - acc: 0.9628\n",
      " 47/100 [=============>................] - ETA: 2s - loss: 0.1043 - acc: 0.9604\n",
      " 57/100 [================>.............] - ETA: 1s - loss: 0.1061 - acc: 0.9611\n",
      " 62/100 [=================>............] - ETA: 1s - loss: 0.1050 - acc: 0.9612\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.1083 - acc: 0.9616\n",
      " 77/100 [======================>.......] - ETA: 0s - loss: 0.1091 - acc: 0.9614\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.1076 - acc: 0.9613\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.1048 - acc: 0.9622\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.1030 - acc: 0.9628\n",
      "Epoch 64/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 1s - loss: 0.0335 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0957 - acc: 0.9588\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0979 - acc: 0.9633\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0989 - acc: 0.9639\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.0972 - acc: 0.9638\n",
      " 47/100 [=============>................] - ETA: 0s - loss: 0.1020 - acc: 0.9641\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.1035 - acc: 0.9634\n",
      " 63/100 [=================>............] - ETA: 0s - loss: 0.1017 - acc: 0.9635\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0989 - acc: 0.9647\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.0989 - acc: 0.9652\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.1011 - acc: 0.9639\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.0963 - acc: 0.9659\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9665\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0960 - acc: 0.9662\n",
      "Epoch 65/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 1s - loss: 0.1149 - acc: 0.9688\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0807 - acc: 0.9714\n",
      " 22/100 [=====>........................] - ETA: 0s - loss: 0.0991 - acc: 0.9680\n",
      " 31/100 [========>.....................] - ETA: 0s - loss: 0.0952 - acc: 0.9682\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.0958 - acc: 0.9676\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.0945 - acc: 0.9671\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.0948 - acc: 0.9657\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.0935 - acc: 0.9676\n",
      " 75/100 [=====================>........] - ETA: 0s - loss: 0.0931 - acc: 0.9677\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.0941 - acc: 0.9667\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 0.0933 - acc: 0.9668\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9673\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0900 - acc: 0.9677\n",
      "Epoch 66/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1844 - acc: 0.9531\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0800 - acc: 0.9609\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0936 - acc: 0.9625\n",
      " 28/100 [=======>......................] - ETA: 4s - loss: 0.0946 - acc: 0.9643\n",
      " 37/100 [==========>...................] - ETA: 2s - loss: 0.0942 - acc: 0.9649\n",
      " 46/100 [============>.................] - ETA: 2s - loss: 0.0942 - acc: 0.9647\n",
      " 56/100 [===============>..............] - ETA: 1s - loss: 0.0949 - acc: 0.9654\n",
      " 61/100 [=================>............] - ETA: 1s - loss: 0.0948 - acc: 0.9654\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.0914 - acc: 0.9674\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.0928 - acc: 0.9676\n",
      " 88/100 [=========================>....] - ETA: 0s - loss: 0.0958 - acc: 0.9661\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.0948 - acc: 0.9665\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.0954 - acc: 0.9667\n",
      "Epoch 67/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1433 - acc: 0.9062\n",
      " 10/100 [==>...........................] - ETA: 0s - loss: 0.1024 - acc: 0.9672\n",
      " 18/100 [====>.........................] - ETA: 0s - loss: 0.0895 - acc: 0.9635\n",
      " 28/100 [=======>......................] - ETA: 0s - loss: 0.1004 - acc: 0.9598\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.0912 - acc: 0.9631\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.0981 - acc: 0.9613\n",
      " 58/100 [================>.............] - ETA: 0s - loss: 0.1003 - acc: 0.9607\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.1047 - acc: 0.9607\n",
      " 74/100 [=====================>........] - ETA: 0s - loss: 0.1027 - acc: 0.9609\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.1001 - acc: 0.9609\n",
      " 85/100 [========================>.....] - ETA: 0s - loss: 0.1006 - acc: 0.9619\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.1036 - acc: 0.9617\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1040 - acc: 0.9617\n",
      "Epoch 68/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0730 - acc: 0.9844\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.1034 - acc: 0.9648\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.1027 - acc: 0.9621\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 0.0983 - acc: 0.9624\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.0908 - acc: 0.9639\n",
      " 46/100 [============>.................] - ETA: 0s - loss: 0.0991 - acc: 0.9637\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.0954 - acc: 0.9659\n",
      " 63/100 [=================>............] - ETA: 0s - loss: 0.0940 - acc: 0.9668\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.0952 - acc: 0.9666\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.0961 - acc: 0.9668\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0946 - acc: 0.9670\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0937 - acc: 0.9667\n",
      "Epoch 69/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0665 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0913 - acc: 0.9716\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.0941 - acc: 0.9628\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.1020 - acc: 0.9630\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.1045 - acc: 0.9624\n",
      " 42/100 [===========>..................] - ETA: 2s - loss: 0.1086 - acc: 0.9583\n",
      " 51/100 [==============>...............] - ETA: 1s - loss: 0.1073 - acc: 0.9596\n",
      " 61/100 [=================>............] - ETA: 1s - loss: 0.1031 - acc: 0.9613\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.1040 - acc: 0.9616\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.1033 - acc: 0.9619\n",
      " 87/100 [=========================>....] - ETA: 0s - loss: 0.1039 - acc: 0.9614\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.1019 - acc: 0.9619\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1008 - acc: 0.9625\n",
      "Epoch 70/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.2512 - acc: 0.9531\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0948 - acc: 0.9702\n",
      " 19/100 [====>.........................] - ETA: 0s - loss: 0.0996 - acc: 0.9655\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0982 - acc: 0.9666\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.1050 - acc: 0.9655\n",
      " 45/100 [============>.................] - ETA: 0s - loss: 0.0991 - acc: 0.9667\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.1005 - acc: 0.9659\n",
      " 63/100 [=================>............] - ETA: 0s - loss: 0.0972 - acc: 0.9668\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.1036 - acc: 0.9642\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.1037 - acc: 0.9640\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.1048 - acc: 0.9648\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9665\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1004 - acc: 0.9664\n",
      "Epoch 71/100\n",
      "\n",
      "Evaluation epoch[70] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 28:29 - loss: 0.0917 - acc: 0.9375\n",
      " 10/100 [==>...........................] - ETA: 2:35 - loss: 0.0871 - acc: 0.9625 \n",
      " 18/100 [====>.........................] - ETA: 1:19 - loss: 0.0871 - acc: 0.9679\n",
      " 26/100 [======>.......................] - ETA: 49s - loss: 0.0799 - acc: 0.9694 \n",
      " 34/100 [=========>....................] - ETA: 33s - loss: 0.0825 - acc: 0.9678\n",
      " 42/100 [===========>..................] - ETA: 24s - loss: 0.0899 - acc: 0.9669\n",
      " 51/100 [==============>...............] - ETA: 16s - loss: 0.0884 - acc: 0.9660\n",
      " 60/100 [=================>............] - ETA: 11s - loss: 0.0931 - acc: 0.9656\n",
      " 68/100 [===================>..........] - ETA: 8s - loss: 0.0907 - acc: 0.9660 \n",
      " 77/100 [======================>.......] - ETA: 5s - loss: 0.0980 - acc: 0.9637\n",
      " 85/100 [========================>.....] - ETA: 3s - loss: 0.1039 - acc: 0.9623\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.1069 - acc: 0.9617\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.1051 - acc: 0.9620\n",
      "Epoch 72/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0681 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0830 - acc: 0.9688\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0905 - acc: 0.9625\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.0889 - acc: 0.9624\n",
      " 36/100 [=========>....................] - ETA: 0s - loss: 0.0936 - acc: 0.9644\n",
      " 45/100 [============>.................] - ETA: 0s - loss: 0.0989 - acc: 0.9632\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0973 - acc: 0.9645\n",
      " 56/100 [===============>..............] - ETA: 1s - loss: 0.0973 - acc: 0.9651\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.0950 - acc: 0.9652\n",
      " 75/100 [=====================>........] - ETA: 0s - loss: 0.0978 - acc: 0.9642\n",
      " 84/100 [========================>.....] - ETA: 0s - loss: 0.0955 - acc: 0.9645\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0956 - acc: 0.9645\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0966 - acc: 0.9647\n",
      "Epoch 73/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0774 - acc: 0.9844\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0869 - acc: 0.9716\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0971 - acc: 0.9656\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.1005 - acc: 0.9688\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.0965 - acc: 0.9688\n",
      " 45/100 [============>.................] - ETA: 0s - loss: 0.0910 - acc: 0.9691\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.0957 - acc: 0.9668\n",
      " 64/100 [==================>...........] - ETA: 0s - loss: 0.1053 - acc: 0.9668\n",
      " 73/100 [====================>.........] - ETA: 0s - loss: 0.1032 - acc: 0.9673\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.1068 - acc: 0.9670\n",
      " 88/100 [=========================>....] - ETA: 0s - loss: 0.1113 - acc: 0.9648\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.1136 - acc: 0.9648\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1121 - acc: 0.9650\n",
      "Epoch 74/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0784 - acc: 0.9844\n",
      "  8/100 [=>............................] - ETA: 0s - loss: 0.1149 - acc: 0.9551\n",
      " 13/100 [==>...........................] - ETA: 9s - loss: 0.1075 - acc: 0.9579\n",
      " 22/100 [=====>........................] - ETA: 5s - loss: 0.0961 - acc: 0.9631\n",
      " 29/100 [=======>......................] - ETA: 3s - loss: 0.1101 - acc: 0.9617\n",
      " 37/100 [==========>...................] - ETA: 2s - loss: 0.1060 - acc: 0.9620\n",
      " 45/100 [============>.................] - ETA: 2s - loss: 0.1025 - acc: 0.9622\n",
      " 53/100 [==============>...............] - ETA: 1s - loss: 0.1048 - acc: 0.9614\n",
      " 62/100 [=================>............] - ETA: 1s - loss: 0.0987 - acc: 0.9637\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.1013 - acc: 0.9633\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.0989 - acc: 0.9647\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0966 - acc: 0.9651\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.1042 - acc: 0.9630\n",
      "Epoch 75/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1172 - acc: 0.9375\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0953 - acc: 0.9616\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.0894 - acc: 0.9635\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0933 - acc: 0.9644\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.0912 - acc: 0.9643\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.0942 - acc: 0.9629\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.0954 - acc: 0.9629\n",
      " 64/100 [==================>...........] - ETA: 0s - loss: 0.0971 - acc: 0.9626\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.0956 - acc: 0.9629\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.0991 - acc: 0.9626\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 0.1002 - acc: 0.9618\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.1000 - acc: 0.9620\n",
      "Epoch 76/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0388 - acc: 1.0000\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.1116 - acc: 0.9588\n",
      " 17/100 [====>.........................] - ETA: 0s - loss: 0.1251 - acc: 0.9605\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1106 - acc: 0.9630\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.1051 - acc: 0.9637\n",
      " 47/100 [=============>................] - ETA: 0s - loss: 0.1023 - acc: 0.9631\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.1034 - acc: 0.9624\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.1073 - acc: 0.9626\n",
      " 76/100 [=====================>........] - ETA: 0s - loss: 0.1062 - acc: 0.9622\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.1083 - acc: 0.9611\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.1054 - acc: 0.9621\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1046 - acc: 0.9622\n",
      "Epoch 77/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0624 - acc: 0.9531\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.1129 - acc: 0.9544\n",
      " 22/100 [=====>........................] - ETA: 0s - loss: 0.0962 - acc: 0.9609\n",
      " 27/100 [=======>......................] - ETA: 5s - loss: 0.0927 - acc: 0.9612\n",
      " 36/100 [=========>....................] - ETA: 3s - loss: 0.0910 - acc: 0.9640\n",
      " 45/100 [============>.................] - ETA: 2s - loss: 0.0867 - acc: 0.9660\n",
      " 54/100 [===============>..............] - ETA: 1s - loss: 0.0873 - acc: 0.9659\n",
      " 63/100 [=================>............] - ETA: 1s - loss: 0.0922 - acc: 0.9658\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.0969 - acc: 0.9638\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.0954 - acc: 0.9655\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0973 - acc: 0.9646\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9642\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.1007 - acc: 0.9642\n",
      "Epoch 78/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 1s - loss: 0.0765 - acc: 0.9688\n",
      " 10/100 [==>...........................] - ETA: 0s - loss: 0.0914 - acc: 0.9547\n",
      " 18/100 [====>.........................] - ETA: 0s - loss: 0.0975 - acc: 0.9601\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1060 - acc: 0.9589\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.1113 - acc: 0.9590\n",
      " 47/100 [=============>................] - ETA: 0s - loss: 0.1104 - acc: 0.9621\n",
      " 56/100 [===============>..............] - ETA: 0s - loss: 0.1083 - acc: 0.9637\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.1039 - acc: 0.9647\n",
      " 75/100 [=====================>........] - ETA: 0s - loss: 0.1022 - acc: 0.9654\n",
      " 83/100 [=======================>......] - ETA: 0s - loss: 0.1017 - acc: 0.9639\n",
      " 84/100 [========================>.....] - ETA: 0s - loss: 0.1014 - acc: 0.9639\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.0986 - acc: 0.9640\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9643\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.1028 - acc: 0.9641\n",
      "Epoch 79/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 1s - loss: 0.1392 - acc: 0.9375\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.1147 - acc: 0.9609\n",
      " 22/100 [=====>........................] - ETA: 0s - loss: 0.0957 - acc: 0.9659\n",
      " 31/100 [========>.....................] - ETA: 0s - loss: 0.0932 - acc: 0.9632\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.0960 - acc: 0.9619\n",
      " 44/100 [============>.................] - ETA: 0s - loss: 0.0983 - acc: 0.9620\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.0987 - acc: 0.9624\n",
      " 64/100 [==================>...........] - ETA: 0s - loss: 0.0968 - acc: 0.9641\n",
      " 76/100 [=====================>........] - ETA: 0s - loss: 0.0991 - acc: 0.9644\n",
      " 84/100 [========================>.....] - ETA: 0s - loss: 0.0980 - acc: 0.9648\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.0979 - acc: 0.9654\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0955 - acc: 0.9659\n",
      "Epoch 80/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0773 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0996 - acc: 0.9616\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0807 - acc: 0.9695\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0943 - acc: 0.9698\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.0896 - acc: 0.9704\n",
      " 41/100 [===========>..................] - ETA: 2s - loss: 0.0882 - acc: 0.9699\n",
      " 50/100 [==============>...............] - ETA: 1s - loss: 0.0876 - acc: 0.9691\n",
      " 59/100 [================>.............] - ETA: 1s - loss: 0.0881 - acc: 0.9680\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0885 - acc: 0.9667\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0889 - acc: 0.9668\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.0903 - acc: 0.9670\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0910 - acc: 0.9669\n",
      "Epoch 81/100\n",
      "\n",
      "Evaluation epoch[80] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 29:33 - loss: 0.3077 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 2:25 - loss: 0.1223 - acc: 0.9616 \n",
      " 20/100 [=====>........................] - ETA: 1:12 - loss: 0.1007 - acc: 0.9688\n",
      " 29/100 [=======>......................] - ETA: 44s - loss: 0.0959 - acc: 0.9677 \n",
      " 37/100 [==========>...................] - ETA: 30s - loss: 0.0961 - acc: 0.9666\n",
      " 43/100 [===========>..................] - ETA: 24s - loss: 0.0925 - acc: 0.9666\n",
      " 52/100 [==============>...............] - ETA: 16s - loss: 0.0980 - acc: 0.9642\n",
      " 60/100 [=================>............] - ETA: 12s - loss: 0.0971 - acc: 0.9659\n",
      " 69/100 [===================>..........] - ETA: 8s - loss: 0.0992 - acc: 0.9658 \n",
      " 78/100 [======================>.......] - ETA: 5s - loss: 0.0952 - acc: 0.9661\n",
      " 87/100 [=========================>....] - ETA: 2s - loss: 0.0953 - acc: 0.9666\n",
      " 93/100 [==========================>...] - ETA: 1s - loss: 0.0952 - acc: 0.9669\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9664\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 0.0951 - acc: 0.9666\n",
      "Epoch 82/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1831 - acc: 0.9219\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0971 - acc: 0.9588\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0836 - acc: 0.9648\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.0857 - acc: 0.9651\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.0901 - acc: 0.9651\n",
      " 50/100 [==============>...............] - ETA: 0s - loss: 0.0896 - acc: 0.9663\n",
      " 59/100 [================>.............] - ETA: 0s - loss: 0.0953 - acc: 0.9648\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.0958 - acc: 0.9642\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.1028 - acc: 0.9628\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.1036 - acc: 0.9612\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9620\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1011 - acc: 0.9617\n",
      "Epoch 83/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0429 - acc: 0.9844\n",
      " 10/100 [==>...........................] - ETA: 0s - loss: 0.0955 - acc: 0.9656\n",
      " 19/100 [====>.........................] - ETA: 0s - loss: 0.0954 - acc: 0.9663\n",
      " 28/100 [=======>......................] - ETA: 0s - loss: 0.0976 - acc: 0.9626\n",
      " 37/100 [==========>...................] - ETA: 0s - loss: 0.0916 - acc: 0.9645\n",
      " 46/100 [============>.................] - ETA: 0s - loss: 0.1013 - acc: 0.9643\n",
      " 54/100 [===============>..............] - ETA: 0s - loss: 0.1054 - acc: 0.9638\n",
      " 55/100 [===============>..............] - ETA: 1s - loss: 0.1095 - acc: 0.9628\n",
      " 64/100 [==================>...........] - ETA: 1s - loss: 0.1040 - acc: 0.9634\n",
      " 74/100 [=====================>........] - ETA: 0s - loss: 0.1018 - acc: 0.9643\n",
      " 83/100 [=======================>......] - ETA: 0s - loss: 0.1085 - acc: 0.9644\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.1092 - acc: 0.9650\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.1083 - acc: 0.9645\n",
      "Epoch 84/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.3464 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.1183 - acc: 0.9616\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.1185 - acc: 0.9602\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.1135 - acc: 0.9625\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.1129 - acc: 0.9627\n",
      " 49/100 [=============>................] - ETA: 0s - loss: 0.1092 - acc: 0.9627\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.1101 - acc: 0.9641\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.1056 - acc: 0.9645\n",
      " 74/100 [=====================>........] - ETA: 0s - loss: 0.1047 - acc: 0.9652\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.1099 - acc: 0.9646\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 0.1093 - acc: 0.9637\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1080 - acc: 0.9647\n",
      "Epoch 85/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1336 - acc: 0.9219\n",
      "  9/100 [=>............................] - ETA: 0s - loss: 0.1459 - acc: 0.9549\n",
      " 12/100 [==>...........................] - ETA: 11s - loss: 0.1327 - acc: 0.9583\n",
      " 21/100 [=====>........................] - ETA: 5s - loss: 0.1249 - acc: 0.9568 \n",
      " 30/100 [========>.....................] - ETA: 3s - loss: 0.1192 - acc: 0.9604\n",
      " 39/100 [==========>...................] - ETA: 2s - loss: 0.1124 - acc: 0.9607\n",
      " 49/100 [=============>................] - ETA: 1s - loss: 0.1065 - acc: 0.9611\n",
      " 59/100 [================>.............] - ETA: 1s - loss: 0.1051 - acc: 0.9637\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1075 - acc: 0.9631\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.1028 - acc: 0.9642\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.1020 - acc: 0.9645\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9650\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0985 - acc: 0.9652\n",
      "Epoch 86/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1215 - acc: 0.9844\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0869 - acc: 0.9688\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.0873 - acc: 0.9710\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.0829 - acc: 0.9708\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.0893 - acc: 0.9663\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.0914 - acc: 0.9658\n",
      " 58/100 [================>.............] - ETA: 0s - loss: 0.0974 - acc: 0.9661\n",
      " 65/100 [==================>...........] - ETA: 0s - loss: 0.1022 - acc: 0.9661\n",
      " 69/100 [===================>..........] - ETA: 0s - loss: 0.1029 - acc: 0.9667\n",
      " 76/100 [=====================>........] - ETA: 0s - loss: 0.1107 - acc: 0.9657\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.1110 - acc: 0.9655\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.1098 - acc: 0.9653\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.1091 - acc: 0.9650\n",
      "Epoch 87/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1241 - acc: 0.9531\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.1137 - acc: 0.9631\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.1041 - acc: 0.9665\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.0995 - acc: 0.9661\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.0968 - acc: 0.9660\n",
      " 49/100 [=============>................] - ETA: 0s - loss: 0.0962 - acc: 0.9662\n",
      " 58/100 [================>.............] - ETA: 0s - loss: 0.1006 - acc: 0.9655\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.0999 - acc: 0.9658\n",
      " 74/100 [=====================>........] - ETA: 0s - loss: 0.1082 - acc: 0.9645\n",
      " 83/100 [=======================>......] - ETA: 0s - loss: 0.1073 - acc: 0.9655\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.1061 - acc: 0.9660\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1048 - acc: 0.9658\n",
      "Epoch 88/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0453 - acc: 0.9844\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0730 - acc: 0.9730\n",
      " 19/100 [====>.........................] - ETA: 0s - loss: 0.0798 - acc: 0.9737\n",
      " 26/100 [======>.......................] - ETA: 4s - loss: 0.1018 - acc: 0.9694\n",
      " 36/100 [=========>....................] - ETA: 2s - loss: 0.0994 - acc: 0.9674\n",
      " 44/100 [============>.................] - ETA: 2s - loss: 0.0998 - acc: 0.9656\n",
      " 54/100 [===============>..............] - ETA: 1s - loss: 0.0998 - acc: 0.9664\n",
      " 63/100 [=================>............] - ETA: 1s - loss: 0.0968 - acc: 0.9660\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.0986 - acc: 0.9664\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.1012 - acc: 0.9658\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.0989 - acc: 0.9665\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9675\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0973 - acc: 0.9673\n",
      "Epoch 89/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1866 - acc: 0.9531\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0958 - acc: 0.9622\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.1087 - acc: 0.9591\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.1225 - acc: 0.9583\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.1125 - acc: 0.9595\n",
      " 49/100 [=============>................] - ETA: 0s - loss: 0.1074 - acc: 0.9611\n",
      " 58/100 [================>.............] - ETA: 0s - loss: 0.1064 - acc: 0.9612\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.1028 - acc: 0.9621\n",
      " 76/100 [=====================>........] - ETA: 0s - loss: 0.1013 - acc: 0.9636\n",
      " 83/100 [=======================>......] - ETA: 0s - loss: 0.0998 - acc: 0.9631\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.0981 - acc: 0.9630\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0975 - acc: 0.9630\n",
      "Epoch 90/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0136 - acc: 1.0000\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.0867 - acc: 0.9661\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.1099 - acc: 0.9609\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.0934 - acc: 0.9682\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.1061 - acc: 0.9650\n",
      " 47/100 [=============>................] - ETA: 0s - loss: 0.1092 - acc: 0.9641\n",
      " 57/100 [================>.............] - ETA: 0s - loss: 0.1131 - acc: 0.9633\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.1107 - acc: 0.9648\n",
      " 77/100 [======================>.......] - ETA: 0s - loss: 0.1045 - acc: 0.9665\n",
      " 87/100 [=========================>....] - ETA: 0s - loss: 0.1016 - acc: 0.9673\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.1016 - acc: 0.9673\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1023 - acc: 0.9666\n",
      "Epoch 91/100\n",
      "\n",
      "Evaluation epoch[90] metrics[0.10, 0.96] ['loss', 'acc']\n",
      "\n",
      "  1/100 [..............................] - ETA: 31:02 - loss: 0.3381 - acc: 0.9531\n",
      " 10/100 [==>...........................] - ETA: 2:49 - loss: 0.1691 - acc: 0.9453 \n",
      " 19/100 [====>.........................] - ETA: 1:20 - loss: 0.1300 - acc: 0.9572\n",
      " 27/100 [=======>......................] - ETA: 51s - loss: 0.1264 - acc: 0.9606 \n",
      " 34/100 [=========>....................] - ETA: 36s - loss: 0.1460 - acc: 0.9577\n",
      " 40/100 [===========>..................] - ETA: 30s - loss: 0.1441 - acc: 0.9578\n",
      " 49/100 [=============>................] - ETA: 21s - loss: 0.1316 - acc: 0.9601\n",
      " 57/100 [================>.............] - ETA: 15s - loss: 0.1262 - acc: 0.9589\n",
      " 66/100 [==================>...........] - ETA: 10s - loss: 0.1253 - acc: 0.9583\n",
      " 74/100 [=====================>........] - ETA: 7s - loss: 0.1221 - acc: 0.9578 \n",
      " 83/100 [=======================>......] - ETA: 4s - loss: 0.1225 - acc: 0.9590\n",
      " 92/100 [==========================>...] - ETA: 1s - loss: 0.1198 - acc: 0.9603\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 0.1145 - acc: 0.9619\n",
      "Epoch 92/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1091 - acc: 0.9375\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0943 - acc: 0.9574\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.1157 - acc: 0.9648\n",
      " 29/100 [=======>......................] - ETA: 0s - loss: 0.1127 - acc: 0.9644\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 0.1214 - acc: 0.9623\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.1265 - acc: 0.9616\n",
      " 58/100 [================>.............] - ETA: 0s - loss: 0.1244 - acc: 0.9617\n",
      " 67/100 [===================>..........] - ETA: 0s - loss: 0.1177 - acc: 0.9627\n",
      " 77/100 [======================>.......] - ETA: 0s - loss: 0.1144 - acc: 0.9631\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.1117 - acc: 0.9642\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.1120 - acc: 0.9645\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9650\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1088 - acc: 0.9653\n",
      "Epoch 93/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1259 - acc: 0.9375\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.1351 - acc: 0.9570\n",
      " 22/100 [=====>........................] - ETA: 0s - loss: 0.1326 - acc: 0.9609\n",
      " 31/100 [========>.....................] - ETA: 0s - loss: 0.1172 - acc: 0.9632\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.1139 - acc: 0.9638\n",
      " 50/100 [==============>...............] - ETA: 0s - loss: 0.1138 - acc: 0.9650\n",
      " 61/100 [=================>............] - ETA: 0s - loss: 0.1078 - acc: 0.9667\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.1094 - acc: 0.9657\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.1098 - acc: 0.9658\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.1070 - acc: 0.9663\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9648\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1096 - acc: 0.9644\n",
      "Epoch 94/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1097 - acc: 0.9531\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0903 - acc: 0.9659\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.0849 - acc: 0.9680\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.0876 - acc: 0.9661\n",
      " 40/100 [===========>..................] - ETA: 0s - loss: 0.0845 - acc: 0.9676\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.0893 - acc: 0.9681\n",
      " 54/100 [===============>..............] - ETA: 1s - loss: 0.0908 - acc: 0.9685\n",
      " 62/100 [=================>............] - ETA: 1s - loss: 0.0950 - acc: 0.9655\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.0971 - acc: 0.9654\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 0.0931 - acc: 0.9668\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.0927 - acc: 0.9672\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9665\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0965 - acc: 0.9656\n",
      "Epoch 95/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1447 - acc: 0.9531\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0973 - acc: 0.9631\n",
      " 19/100 [====>.........................] - ETA: 0s - loss: 0.1003 - acc: 0.9638\n",
      " 27/100 [=======>......................] - ETA: 0s - loss: 0.1042 - acc: 0.9612\n",
      " 35/100 [=========>....................] - ETA: 0s - loss: 0.0953 - acc: 0.9647\n",
      " 45/100 [============>.................] - ETA: 0s - loss: 0.0999 - acc: 0.9625\n",
      " 55/100 [===============>..............] - ETA: 0s - loss: 0.1062 - acc: 0.9611\n",
      " 64/100 [==================>...........] - ETA: 0s - loss: 0.1063 - acc: 0.9617\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.1051 - acc: 0.9620\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.1043 - acc: 0.9628\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 0.1010 - acc: 0.9644\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9651\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0972 - acc: 0.9647\n",
      "Epoch 96/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0625 - acc: 0.9688\n",
      "  9/100 [=>............................] - ETA: 0s - loss: 0.1121 - acc: 0.9583\n",
      " 11/100 [==>...........................] - ETA: 12s - loss: 0.1034 - acc: 0.9602\n",
      " 21/100 [=====>........................] - ETA: 6s - loss: 0.0926 - acc: 0.9621 \n",
      " 30/100 [========>.....................] - ETA: 3s - loss: 0.0898 - acc: 0.9635\n",
      " 39/100 [==========>...................] - ETA: 2s - loss: 0.0862 - acc: 0.9655\n",
      " 48/100 [=============>................] - ETA: 1s - loss: 0.0914 - acc: 0.9642\n",
      " 55/100 [===============>..............] - ETA: 1s - loss: 0.0902 - acc: 0.9648\n",
      " 64/100 [==================>...........] - ETA: 1s - loss: 0.0926 - acc: 0.9651\n",
      " 72/100 [====================>.........] - ETA: 0s - loss: 0.0972 - acc: 0.9644\n",
      " 81/100 [=======================>......] - ETA: 0s - loss: 0.0994 - acc: 0.9637\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 0.1033 - acc: 0.9630\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.1085 - acc: 0.9627\n",
      "Epoch 97/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1726 - acc: 0.9062\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.1159 - acc: 0.9474\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.1060 - acc: 0.9576\n",
      " 31/100 [========>.....................] - ETA: 0s - loss: 0.0909 - acc: 0.9637\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 0.1009 - acc: 0.9611\n",
      " 50/100 [==============>...............] - ETA: 0s - loss: 0.0973 - acc: 0.9625\n",
      " 59/100 [================>.............] - ETA: 0s - loss: 0.0978 - acc: 0.9629\n",
      " 66/100 [==================>...........] - ETA: 0s - loss: 0.0955 - acc: 0.9645\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.0951 - acc: 0.9648\n",
      " 77/100 [======================>.......] - ETA: 0s - loss: 0.0938 - acc: 0.9659\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.0976 - acc: 0.9658\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 0.0970 - acc: 0.9666\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.0956 - acc: 0.9666\n",
      "Epoch 98/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.1689 - acc: 0.9219\n",
      " 12/100 [==>...........................] - ETA: 0s - loss: 0.1059 - acc: 0.9544\n",
      " 21/100 [=====>........................] - ETA: 0s - loss: 0.1160 - acc: 0.9613\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.1139 - acc: 0.9620\n",
      " 35/100 [=========>....................] - ETA: 0s - loss: 0.1229 - acc: 0.9603\n",
      " 43/100 [===========>..................] - ETA: 0s - loss: 0.1188 - acc: 0.9618\n",
      " 52/100 [==============>...............] - ETA: 0s - loss: 0.1106 - acc: 0.9639\n",
      " 61/100 [=================>............] - ETA: 0s - loss: 0.1108 - acc: 0.9629\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 0.1103 - acc: 0.9627\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 0.1118 - acc: 0.9619\n",
      " 86/100 [========================>.....] - ETA: 0s - loss: 0.1104 - acc: 0.9620\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.1108 - acc: 0.9622\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1080 - acc: 0.9633\n",
      "Epoch 99/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0918 - acc: 0.9688\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.0787 - acc: 0.9616\n",
      " 19/100 [====>.........................] - ETA: 0s - loss: 0.0763 - acc: 0.9679\n",
      " 25/100 [======>.......................] - ETA: 5s - loss: 0.0855 - acc: 0.9669\n",
      " 34/100 [=========>....................] - ETA: 3s - loss: 0.0903 - acc: 0.9655\n",
      " 42/100 [===========>..................] - ETA: 2s - loss: 0.0916 - acc: 0.9661\n",
      " 51/100 [==============>...............] - ETA: 1s - loss: 0.0993 - acc: 0.9654\n",
      " 59/100 [================>.............] - ETA: 1s - loss: 0.0985 - acc: 0.9658\n",
      " 67/100 [===================>..........] - ETA: 1s - loss: 0.0999 - acc: 0.9648\n",
      " 76/100 [=====================>........] - ETA: 0s - loss: 0.0965 - acc: 0.9650\n",
      " 85/100 [========================>.....] - ETA: 0s - loss: 0.0949 - acc: 0.9654\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.1004 - acc: 0.9652\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0987 - acc: 0.9658\n",
      "Epoch 100/100\n",
      "\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.0342 - acc: 1.0000\n",
      " 11/100 [==>...........................] - ETA: 0s - loss: 0.1317 - acc: 0.9616\n",
      " 20/100 [=====>........................] - ETA: 0s - loss: 0.1287 - acc: 0.9625\n",
      " 30/100 [========>.....................] - ETA: 0s - loss: 0.1133 - acc: 0.9656\n",
      " 38/100 [==========>...................] - ETA: 0s - loss: 0.1055 - acc: 0.9688\n",
      " 48/100 [=============>................] - ETA: 0s - loss: 0.1149 - acc: 0.9691\n",
      " 58/100 [================>.............] - ETA: 0s - loss: 0.1038 - acc: 0.9704\n",
      " 68/100 [===================>..........] - ETA: 0s - loss: 0.1050 - acc: 0.9674\n",
      " 76/100 [=====================>........] - ETA: 0s - loss: 0.1042 - acc: 0.9673\n",
      " 82/100 [=======================>......] - ETA: 0s - loss: 0.1005 - acc: 0.9684\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 0.1010 - acc: 0.9675\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.1020 - acc: 0.9666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "2018-03-02 11:12:35.866713: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/keras/callbacks.py:435: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/churn_neural_net/churn_trained\n",
    "rm -rf vehicles.tar.gz churn_trained\n",
    "gcloud ml-engine local train \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=${REPO}/trainer \\\n",
    "  --job-dir $OUTDIR \\\n",
    "  -- \\\n",
    "  --train_files=${REPO}/churn-train.csv \\\n",
    "  --eval_files=${REPO}/churn-valid.csv  \\\n",
    "  --num_epochs=100 \\\n",
    "  --output_dir=${REPO}/churn_trained \\\n",
    "  --train_steps=100 \\\n",
    "  --eval_steps=100 \\\n",
    "  --train_batch_size=40 \\\n",
    "  --eval_batch_size=40 \\\n",
    "  --learning_rate=0.003 \\\n",
    "  --first_layer_size=256 \\\n",
    "  --num_layers=5 \\\n",
    "  --scale_factor=0.25 \\\n",
    "  --eval_num_epochs=1 \\\n",
    "  --checkpoint_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn_models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://churn_models/churn_cloud/churn-test.csv#1519989783686695...\n",
      "Removing gs://churn_models/churn_cloud/churn-train.csv#1519989797011943...\n",
      "Removing gs://churn_models/churn_cloud/churn-valid.csv#1519989784288344...\n",
      "Removing gs://churn_models/churn_cloud/churn_trained/#1519990036252045...\n",
      "Removing gs://churn_models/churn_cloud/churn_trained/logs/#1519990036522281...\n",
      "Removing gs://churn_models/churn_cloud/churn_trained/logs/events.out.tfevents.1519990036.cmle-training-master-0c36429443-0-ttlm4#1519990281648101...\n",
      "/ [1/6 objects]  16% Done                                                       \r",
      "/ [2/6 objects]  33% Done                                                       \r",
      "/ [3/6 objects]  50% Done                                                       \r",
      "/ [4/6 objects]  66% Done                                                       \r",
      "/ [5/6 objects]  83% Done                                                       \r",
      "/ [6/6 objects] 100% Done                                                       \r\n",
      "Operation completed over 6 objects.                                              \n",
      "Copying file:///content/datalab/churn-test.csv [Content-Type=text/csv]...\n",
      "Copying file:///content/datalab/churn-train.csv [Content-Type=text/csv]...\n",
      "/ [0 files][    0.0 B/248.8 MiB]                                                \r",
      "/ [0/3 files][    0.0 B/  1.2 GiB]   0% Done                                    \r",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file:///content/datalab/churn-valid.csv [Content-Type=text/csv]...\n",
      "/ [0/3 files][    0.0 B/  1.2 GiB]   0% Done                                    \r",
      "-\r",
      "- [0/3 files][ 52.9 MiB/  1.2 GiB]   4% Done                                    \r",
      "\\\r",
      "|\r",
      "| [0/3 files][119.4 MiB/  1.2 GiB]   9% Done                                    \r",
      "/\r",
      "/ [0/3 files][182.0 MiB/  1.2 GiB]  14% Done                                    \r",
      "-\r",
      "\\\r",
      "\\ [0/3 files][238.7 MiB/  1.2 GiB]  19% Done                                    \r",
      "|\r",
      "/\r",
      "/ [0/3 files][298.0 MiB/  1.2 GiB]  23% Done                                    \r",
      "-\r",
      "- [0/3 files][361.7 MiB/  1.2 GiB]  29% Done                                    \r",
      "\\\r",
      "|\r",
      "| [0/3 files][422.8 MiB/  1.2 GiB]  33% Done                                    \r",
      "/\r",
      "-\r",
      "- [0/3 files][481.6 MiB/  1.2 GiB]  38% Done                                    \r",
      "\\\r",
      "\\ [0/3 files][545.5 MiB/  1.2 GiB]  43% Done                                    \r",
      "|\r",
      "/\r",
      "/ [0/3 files][602.3 MiB/  1.2 GiB]  48% Done                                    \r",
      "-\r",
      "\\\r",
      "\\ [0/3 files][664.4 MiB/  1.2 GiB]  53% Done  60.3 MiB/s ETA 00:00:10           \r",
      "|\r",
      "| [0/3 files][726.3 MiB/  1.2 GiB]  58% Done  60.5 MiB/s ETA 00:00:09           \r",
      "/\r",
      "/ [1/3 files][748.2 MiB/  1.2 GiB]  60% Done  60.6 MiB/s ETA 00:00:08           \r",
      "/ [2/3 files][756.7 MiB/  1.2 GiB]  60% Done  59.7 MiB/s ETA 00:00:08           \r",
      "-\r",
      "\\\r",
      "\\ [2/3 files][800.0 MiB/  1.2 GiB]  64% Done  55.9 MiB/s ETA 00:00:08           \r",
      "|\r",
      "/\r",
      "/ [2/3 files][844.3 MiB/  1.2 GiB]  67% Done  52.6 MiB/s ETA 00:00:08           \r",
      "-\r",
      "- [2/3 files][889.5 MiB/  1.2 GiB]  71% Done  50.0 MiB/s ETA 00:00:07           \r",
      "\\\r",
      "|\r",
      "| [2/3 files][933.6 MiB/  1.2 GiB]  75% Done  46.4 MiB/s ETA 00:00:07           \r",
      "/\r",
      "-\r",
      "- [2/3 files][977.6 MiB/  1.2 GiB]  78% Done  44.1 MiB/s ETA 00:00:06           \r",
      "\\\r",
      "\\ [2/3 files][ 1021 MiB/  1.2 GiB]  82% Done  44.2 MiB/s ETA 00:00:05           \r",
      "|\r",
      "/\r",
      "/ [2/3 files][  1.0 GiB/  1.2 GiB]  85% Done  44.1 MiB/s ETA 00:00:04           \r",
      "-\r",
      "\\\r",
      "\\ [2/3 files][  1.1 GiB/  1.2 GiB]  89% Done  43.5 MiB/s ETA 00:00:03           \r",
      "|\r",
      "| [2/3 files][  1.1 GiB/  1.2 GiB]  92% Done  42.9 MiB/s ETA 00:00:02           \r",
      "/\r",
      "-\r",
      "- [2/3 files][  1.2 GiB/  1.2 GiB]  95% Done  41.6 MiB/s ETA 00:00:01           \r",
      "\\\r",
      "|\r",
      "| [2/3 files][  1.2 GiB/  1.2 GiB]  98% Done  41.5 MiB/s ETA 00:00:00           \r",
      "| [3/3 files][  1.2 GiB/  1.2 GiB] 100% Done  40.5 MiB/s ETA 00:00:00           \r\n",
      "Operation completed over 3 objects/1.2 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/churn_cloud\n",
    "gsutil -m cp ${REPO}/*.csv gs://${BUCKET}/churn_cloud/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://churn_models/churn_cloud/churn_trained europe-west1 churn_model_180302_113150\n",
      "jobId: churn_model_180302_113150\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://churn_models/churn_cloud/churn_trained/logs/events.out.tfevents.1519990036.cmle-training-master-0c36429443-0-ttlm4#1519990282487373...\n",
      "/ [1/1 objects] 100% Done                                                       \r\n",
      "Operation completed over 1 objects.                                              \n",
      "/tools/google-cloud-sdk/lib/googlecloudsdk/core/util/files.py:622: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  for chunk in iter(lambda: fp.read(4096), ''):\n",
      "Job [churn_model_180302_113150] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe churn_model_180302_113150\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs churn_model_180302_113150\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/churn_cloud/churn_trained\n",
    "JOBNAME=churn_model_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=${REPO}/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=BASIC \\\n",
    "  --runtime-version=1.2 \\\n",
    "  -- \\\n",
    "  --train_files=\"gs://${BUCKET}/churn_cloud/churn-train.csv\" \\\n",
    "  --eval_files=\"gs://${BUCKET}/churn_cloud/churn-valid.csv\"  \\\n",
    "  --num_epochs=100 \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --train_steps=100 \\\n",
    "  --eval_steps=100 \\\n",
    "  --train_batch_size=40 \\\n",
    "  --eval_batch_size=40 \\\n",
    "  --learning_rate=0.003 \\\n",
    "  --first_layer_size=256 \\\n",
    "  --num_layers=5 \\\n",
    "  --scale_factor=0.25 \\\n",
    "  --eval_num_epochs=1 \\\n",
    "  --checkpoint_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  parser.add_argument('--train_files',\r\n",
      "                      required=True,\r\n",
      "                      type=str,\r\n",
      "--\r\n",
      "  parser.add_argument('--eval_files',\r\n",
      "                      required=True,\r\n",
      "                      type=str,\r\n",
      "--\r\n",
      "  parser.add_argument('--job-dir',\r\n",
      "                      required=True,\r\n",
      "                      type=str,\r\n",
      "--\r\n",
      "  parser.add_argument('--train_steps',\r\n",
      "                      type=int,\r\n",
      "                      default=100,\r\n",
      "--\r\n",
      "  parser.add_argument('--eval_steps',\r\n",
      "                      help='Number of steps to run evalution for at each checkpoint',\r\n",
      "                      default=100,\r\n",
      "--\r\n",
      "  parser.add_argument('--train_batch_size',\r\n",
      "                      type=int,\r\n",
      "                      default=40,\r\n",
      "--\r\n",
      "  parser.add_argument('--eval_batch_size',\r\n",
      "                      type=int,\r\n",
      "                      default=40,\r\n",
      "--\r\n",
      "  parser.add_argument('--learning_rate',\r\n",
      "                      type=float,\r\n",
      "                      default=0.003,\r\n",
      "--\r\n",
      "  parser.add_argument('--eval_frequency',\r\n",
      "                      default=10,\r\n",
      "                      help='Perform one evaluation per n epochs')\r\n",
      "  parser.add_argument('--first_layer_size',\r\n",
      "                     type=int,\r\n",
      "                     default=256,\r\n",
      "--\r\n",
      "  parser.add_argument('--num_layers',\r\n",
      "                     type=int,\r\n",
      "                     default=2,\r\n",
      "--\r\n",
      "  parser.add_argument('--scale_factor',\r\n",
      "                     type=float,\r\n",
      "                     default=0.25,\r\n",
      "--\r\n",
      "  parser.add_argument('--eval_num_epochs',\r\n",
      "                     type=int,\r\n",
      "                     default=1,\r\n",
      "--\r\n",
      "  parser.add_argument('--num_epochs',\r\n",
      "                      type=int,\r\n",
      "                      default=20,\r\n",
      "--\r\n",
      "  parser.add_argument('--checkpoint_epochs',\r\n",
      "                      type=int,\r\n",
      "                      default=5,\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A 2 add_argument trainer/task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!grep -A 5 eval_metric trainer/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    hyperparameterMetricTag: val_ac\n",
    "    maxTrials: 20\n",
    "    maxParallelTrials: 1\n",
    "    params:\n",
    "    - parameterName: train_batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 64\n",
    "      maxValue: 512\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: nbuckets\n",
    "      type: INTEGER\n",
    "      minValue: 10\n",
    "      maxValue: 20\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"128 32\", \"256 128 16\", \"64 64 64 8\"]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn_models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://churn_models/churn_cloud_hyper/churn-test.csv#1519992844377633...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn-train.csv#1519992855910208...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn-valid.csv#1519992844253977...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/#1519992887076735...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/#1519992887266427...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/churn_model.hdf5#1519992898195131...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/export/#1519992898730432...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/export/saved_model.pb#1519992902746240...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/export/variables/#1519992901230111...\n",
      "/ [1/22 objects]   4% Done                                                      \r",
      "/ [2/22 objects]   9% Done                                                      \r",
      "/ [3/22 objects]  13% Done                                                      \r",
      "/ [4/22 objects]  18% Done                                                      \r",
      "/ [5/22 objects]  22% Done                                                      \r",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/export/variables/variables.data-00000-of-00001#1519992901749346...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/export/variables/variables.index#1519992902032502...\n",
      "/ [6/22 objects]  27% Done                                                      \r",
      "/ [7/22 objects]  31% Done                                                      \r",
      "/ [8/22 objects]  36% Done                                                      \r",
      "/ [9/22 objects]  40% Done                                                      \r",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/logs/#1519992887489970...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/1/logs/events.out.tfevents.1519992887.cmle-training-master-16cccb8703-0-dkgzm#1519992897859250...\n",
      "/ [10/22 objects]  45% Done                                                     \r",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/#1519993245559578...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/churn_model.hdf5#1519993256979044...\n",
      "/ [11/22 objects]  50% Done                                                     \r",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/export/#1519993257596283...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/export/saved_model.pb#1519993261230251...\n",
      "/ [12/22 objects]  54% Done                                                     \r",
      "/ [13/22 objects]  59% Done                                                     \r",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/export/variables/#1519993259766559...\n",
      "/ [14/22 objects]  63% Done                                                     \r",
      "/ [15/22 objects]  68% Done                                                     \r",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/export/variables/variables.data-00000-of-00001#1519993260258314...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/export/variables/variables.index#1519993260580810...\n",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/logs/#1519993245839748...\n",
      "/ [16/22 objects]  72% Done                                                     \r",
      "/ [17/22 objects]  77% Done                                                     \r",
      "Removing gs://churn_models/churn_cloud_hyper/churn_trained/2/logs/events.out.tfevents.1519993245.cmle-training-master-71b73e3db9-0-lx6tm#1519993256626751...\n",
      "/ [18/22 objects]  81% Done                                                     \r",
      "/ [19/22 objects]  86% Done                                                     \r",
      "/ [20/22 objects]  90% Done                                                     \r",
      "/ [21/22 objects]  95% Done                                                     \r",
      "/ [22/22 objects] 100% Done                                                     \r\n",
      "Operation completed over 22 objects.                                             \n",
      "Copying file:///content/datalab/churn-test.csv [Content-Type=text/csv]...\n",
      "Copying file:///content/datalab/churn-train.csv [Content-Type=text/csv]...\n",
      "/ [0 files][    0.0 B/248.8 MiB]                                                \r",
      "/ [0/3 files][    0.0 B/  1.2 GiB]   0% Done                                    \r",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file:///content/datalab/churn-valid.csv [Content-Type=text/csv]...\n",
      "/ [0/3 files][    0.0 B/  1.2 GiB]   0% Done                                    \r",
      "-\r",
      "- [0/3 files][ 55.4 MiB/  1.2 GiB]   4% Done                                    \r",
      "\\\r",
      "|\r",
      "| [0/3 files][137.2 MiB/  1.2 GiB]  11% Done                                    \r",
      "/\r",
      "/ [0/3 files][219.1 MiB/  1.2 GiB]  17% Done                                    \r",
      "-\r",
      "\\\r",
      "\\ [0/3 files][297.8 MiB/  1.2 GiB]  23% Done                                    \r",
      "|\r",
      "/\r",
      "/ [0/3 files][379.5 MiB/  1.2 GiB]  30% Done                                    \r",
      "-\r",
      "- [0/3 files][458.9 MiB/  1.2 GiB]  36% Done                                    \r",
      "\\\r",
      "|\r",
      "| [0/3 files][540.1 MiB/  1.2 GiB]  43% Done                                    \r",
      "/\r",
      "-\r",
      "- [0/3 files][619.3 MiB/  1.2 GiB]  49% Done                                    \r",
      "\\\r",
      "\\ [0/3 files][700.2 MiB/  1.2 GiB]  56% Done                                    \r",
      "|\r",
      "| [1/3 files][748.2 MiB/  1.2 GiB]  60% Done                                    \r",
      "/\r",
      "/ [2/3 files][772.9 MiB/  1.2 GiB]  62% Done                                    \r",
      "-\r",
      "\\\r",
      "\\ [2/3 files][825.8 MiB/  1.2 GiB]  66% Done                                    \r",
      "|\r",
      "| [2/3 files][866.0 MiB/  1.2 GiB]  69% Done  65.4 MiB/s ETA 00:00:06           \r",
      "/\r",
      "-\r",
      "- [2/3 files][903.4 MiB/  1.2 GiB]  72% Done  57.1 MiB/s ETA 00:00:06           \r",
      "\\\r",
      "|\r",
      "| [2/3 files][959.1 MiB/  1.2 GiB]  77% Done  52.1 MiB/s ETA 00:00:05           \r",
      "/\r",
      "/ [2/3 files][  1.0 GiB/  1.2 GiB]  82% Done  49.8 MiB/s ETA 00:00:04           \r",
      "-\r",
      "\\\r",
      "\\ [2/3 files][  1.1 GiB/  1.2 GiB]  88% Done  54.9 MiB/s ETA 00:00:03           \r",
      "|\r",
      "/\r",
      "/ [2/3 files][  1.2 GiB/  1.2 GiB]  95% Done  64.2 MiB/s ETA 00:00:01           \r",
      "-\r",
      "- [3/3 files][  1.2 GiB/  1.2 GiB] 100% Done  69.2 MiB/s ETA 00:00:00           \r\n",
      "Operation completed over 3 objects/1.2 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/churn_cloud_hyper\n",
    "gsutil -m cp ${REPO}/*.csv gs://${BUCKET}/churn_cloud_hyper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://churn_models/churn_cloud_hyper/churn_trained europe-west1 churn_model_hyper_180302_123936\n",
      "jobId: churn_model_hyper_180302_123936\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "/tools/google-cloud-sdk/lib/googlecloudsdk/core/util/files.py:622: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  for chunk in iter(lambda: fp.read(4096), ''):\n",
      "Job [churn_model_hyper_180302_123936] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe churn_model_hyper_180302_123936\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs churn_model_hyper_180302_123936\n",
      "bash: line 19: --output_dir=gs://churn_models/churn_cloud_hyper/churn_trained: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/churn_cloud_hyper/churn_trained\n",
    "JOBNAME=churn_model_hyper_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=${REPO}/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=BASIC \\\n",
    "  --runtime-version=1.2 \\\n",
    "  --config=hyperparam.yaml \\\n",
    "  -- \\\n",
    "  --train_files=\"gs://${BUCKET}/churn_cloud_hyper/churn-train.csv\" \\\n",
    "  --eval_files=\"gs://${BUCKET}/churn_cloud_hyper/churn-valid.csv\"  \\\n",
    "  --num_epochs=100\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --train_steps=100 \\\n",
    "  --eval_steps=100 \\\n",
    "  --train_batch_size=40 \\\n",
    "  --eval_batch_size=40 \\\n",
    "  --learning_rate=0.003 \\\n",
    "  --first_layer_size=256 \\\n",
    "  --num_layers=5 \\\n",
    "  --scale_factor=0.25 \\\n",
    "  --eval_num_epochs=1 \\\n",
    "  --checkpoint_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
