{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print tf.__version__\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['check.csv',\n",
       " 'lstm.ipynb',\n",
       " 'lstm 2.0.ipynb',\n",
       " 'intermediate.csv',\n",
       " 'churn_100_customers.csv',\n",
       " 'churn_100_customers_365_days.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'data_sets',\n",
       " 'churn-create-timedependent-data.ipynb',\n",
       " 'churn-time-dependent-artificial-data.csv',\n",
       " 'trainer',\n",
       " 'lstm training.ipynb',\n",
       " 'churn.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT = 'go-de-internal'\n",
    "BUCKET = 'go-de-internal-johanna'\n",
    "REGION = 'europe-west1'\n",
    "REPO = \"/content/datalab/demo-cases/churn-prediction/lstm\"\n",
    "os.listdir(REPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['REPO'] = REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorizing the Cloud ML Service account service-462605511119@cloud-ml.google.com.iam.gserviceaccount.com to access files in go-de-internal-johanna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   133    0   133    0     0    136      0 --:--:-- --:--:-- --:--:--   136\r",
      "100   133    0   133    0     0    136      0 --:--:-- --:--:-- --:--:--   136\n",
      "No changes to gs://go-de-internal-johanna/\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/lstm/\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/lstm/a_b\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/lstm/a_b/\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/lstm/a_b/a_b.csv\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn-einzelhandel-train.csv\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/churn_model.hdf5\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/export/saved_model.pb\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/mv_ab_model_ads_build_sep.csv\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/export/variables/variables.index\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/logs/\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn-einzelhandel-valid.csv\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn-telecommunication.csv\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/export/variables/variables.data-00000-of-00001\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/export/\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn-einzelhandel-test.csv\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/export/variables/\n",
      "No changes to gs://go-de-internal-johanna/churn-prediction/neural_net/churn_trained/logs/events.out.tfevents.1520528756.696604c6b0d9\n",
      "No changes to gs://go-de-internal-johanna/flight-time-estimate/\n",
      "No changes to gs://go-de-internal-johanna/pattern-recognition/\n",
      "No changes to gs://go-de-internal-johanna/vehicles_health_demo_180305_180649/413a63e0e47758abd44b25679856780a0346cc2efadb779f70292c1e8ffd12fa/econsumption-0.1.tar.gz\n",
      "No changes to gs://go-de-internal-johanna/vehicles_health_demo_hyper_param_180305_180703/0712cc9a349f1b7d8b740620452df3c60b430d2647b84bb756e54b883d8f788f/econsumption-0.1.tar.gz\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status/\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status//neural-net/vehicles-test.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status/hyper-param/vehicles-test.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status//neural-net/vehicles-train.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status//neural-net/vehicles-valid.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status/lindeshow-case-data-all.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status/hyper-param/vehicles-train.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status/hyper-param/vehicles-valid.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles-valid.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles-train.csv\n",
      "No changes to gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles-test.csv\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/checkpoint\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/eval/\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/eval/events.out.tfevents.1520273650.cmle-training-master-e97f25bfc7-0-b8t26\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/events.out.tfevents.1520273224.cmle-training-master-e97f25bfc7-0-b8t26\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/export/Servo/\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/eval/events.out.tfevents.1520273232.cmle-training-master-e97f25bfc7-0-b8t26\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/model.ckpt-2100.index\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/model.ckpt-1.data-00000-of-00001\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/graph.pbtxt\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/model.ckpt-2100.data-00000-of-00001\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/export/\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/export/Servo/1520273651560/\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/export/Servo/1520273651560/variables/\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/model.ckpt-1.meta\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/model.ckpt-2100.meta\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/export/Servo/1520273651560/variables/variables.data-00000-of-00001\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/export/Servo/1520273651560/saved_model.pb\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/export/Servo/1520273651560/variables/variables.index\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained/model.ckpt-1.index\n",
      "No changes to gs://go-de-internal-johanna/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print response['serviceAccount']\")\n",
    "\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!cat trainer/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n",
      ",0,1,2,3,4\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "head -1 $REPO/labels.csv\n",
    "head -1 $REPO/training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "DATA_BUCKET='go-de-internal-johanna'\n",
    "FILES = ['training.csv', 'labels.csv']\n",
    "\n",
    "client = storage.Client(project=PROJECT)\n",
    "bucket = client.get_bucket(DATA_BUCKET)\n",
    "\n",
    "for filename in FILES:\n",
    "    with open(filename, 'wb') as f:\n",
    "        bucket.blob(filename).download_to_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1',       Unnamed: 0  0  1  2  3  4\n",
      "0              0  0  0  0  0  0\n",
      "1              1  0  0  0  0  0\n",
      "2              2  0  0  0  0  0\n",
      "3              3  0  0  0  0  0\n",
      "4              4  0  0  0  0  0\n",
      "5              5  0  0  0  0  0\n",
      "6              6  0  0  0  0  0\n",
      "7              7  0  0  0  0  0\n",
      "8              8  0  0  0  0  0\n",
      "9              9  0  0  0  0  0\n",
      "10            10  0  0  0  0  0\n",
      "11            11  0  0  0  0  0\n",
      "12            12  0  0  0  0  0\n",
      "13            13  0  0  0  0  0\n",
      "14            14  0  0  0  0  0\n",
      "15            15  0  0  0  0  0\n",
      "16            16  0  0  0  0  0\n",
      "17            17  0  0  0  0  0\n",
      "18            18  0  0  0  0  0\n",
      "19            19  0  0  0  0  0\n",
      "20            20  0  0  0  0  0\n",
      "21            21  0  0  0  0  0\n",
      "22            22  0  0  0  0  0\n",
      "23            23  0  0  0  0  0\n",
      "24            24  0  0  0  0  0\n",
      "25            25  0  0  0  0  0\n",
      "26            26  0  0  0  0  0\n",
      "27            27  0  0  0  0  0\n",
      "28            28  0  0  0  0  0\n",
      "29            29  0  0  0  0  0\n",
      "...          ... .. .. .. .. ..\n",
      "3310        3310  0  0  0  0  0\n",
      "3311        3311  0  0  0  0  0\n",
      "3312        3312  0  0  0  0  0\n",
      "3313        3313  0  0  0  0  0\n",
      "3314        3314  0  0  0  0  0\n",
      "3315        3315  0  0  0  0  0\n",
      "3316        3316  0  0  0  0  0\n",
      "3317        3317  0  0  0  0  0\n",
      "3318        3318  0  0  0  0  0\n",
      "3319        3319  0  0  0  0  0\n",
      "3320        3320  0  0  0  0  0\n",
      "3321        3321  0  0  0  0  0\n",
      "3322        3322  0  0  0  0  0\n",
      "3323        3323  0  0  0  0  0\n",
      "3324        3324  0  0  0  0  0\n",
      "3325        3325  0  0  0  0  0\n",
      "3326        3326  0  0  0  0  0\n",
      "3327        3327  0  0  0  0  0\n",
      "3328        3328  0  0  0  0  0\n",
      "3329        3329  0  0  0  0  0\n",
      "3330        3330  0  0  0  0  0\n",
      "3331        3331  0  0  0  0  0\n",
      "3332        3332  0  0  0  0  0\n",
      "3333        3333  0  0  0  0  0\n",
      "3334        3334  0  0  0  0  0\n",
      "3335        3335  0  0  0  0  0\n",
      "3336        3336  0  0  0  0  0\n",
      "3337        3337  0  0  0  0  0\n",
      "3338        3338  0  0  0  0  0\n",
      "3339        3339  0  0  0  0  0\n",
      "\n",
      "[3340 rows x 6 columns])\n",
      "('2',       0  1  2  3  4\n",
      "0     0  0  0  0  0\n",
      "1     0  0  0  0  0\n",
      "2     0  0  0  0  0\n",
      "3     0  0  0  0  0\n",
      "4     0  0  0  0  0\n",
      "5     0  0  0  0  0\n",
      "6     0  0  0  0  0\n",
      "7     0  0  0  0  0\n",
      "8     0  0  0  0  0\n",
      "9     0  0  0  0  0\n",
      "10    0  0  0  0  0\n",
      "11    0  0  0  0  0\n",
      "12    0  0  0  0  0\n",
      "13    0  0  0  0  0\n",
      "14    0  0  0  0  0\n",
      "15    0  0  0  0  0\n",
      "16    0  0  0  0  0\n",
      "17    0  0  0  0  0\n",
      "18    0  0  0  0  0\n",
      "19    0  0  0  0  0\n",
      "20    0  0  0  0  0\n",
      "21    0  0  0  0  0\n",
      "22    0  0  0  0  0\n",
      "23    0  0  0  0  0\n",
      "24    0  0  0  0  0\n",
      "25    0  0  0  0  0\n",
      "26    0  0  0  0  0\n",
      "27    0  0  0  0  0\n",
      "28    0  0  0  0  0\n",
      "29    0  0  0  0  0\n",
      "...  .. .. .. .. ..\n",
      "3310  0  0  0  0  0\n",
      "3311  0  0  0  0  0\n",
      "3312  0  0  0  0  0\n",
      "3313  0  0  0  0  0\n",
      "3314  0  0  0  0  0\n",
      "3315  0  0  0  0  0\n",
      "3316  0  0  0  0  0\n",
      "3317  0  0  0  0  0\n",
      "3318  0  0  0  0  0\n",
      "3319  0  0  0  0  0\n",
      "3320  0  0  0  0  0\n",
      "3321  0  0  0  0  0\n",
      "3322  0  0  0  0  0\n",
      "3323  0  0  0  0  0\n",
      "3324  0  0  0  0  0\n",
      "3325  0  0  0  0  0\n",
      "3326  0  0  0  0  0\n",
      "3327  0  0  0  0  0\n",
      "3328  0  0  0  0  0\n",
      "3329  0  0  0  0  0\n",
      "3330  0  0  0  0  0\n",
      "3331  0  0  0  0  0\n",
      "3332  0  0  0  0  0\n",
      "3333  0  0  0  0  0\n",
      "3334  0  0  0  0  0\n",
      "3335  0  0  0  0  0\n",
      "3336  0  0  0  0  0\n",
      "3337  0  0  0  0  0\n",
      "3338  0  0  0  0  0\n",
      "3339  0  0  0  0  0\n",
      "\n",
      "[3340 rows x 5 columns])\n",
      "('3', array([[[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1, 2, 0],\n",
      "        [2, 3, 4, 0, 1],\n",
      "        [3, 2, 2, 1, 1]],\n",
      "\n",
      "       [[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]]), (10, 334, 5))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training = pd.read_csv('training.csv')\n",
    "print('1', training)\n",
    "training = training.iloc[:,1:] #  remove useless first column\n",
    "labels = pd.read_csv('labels.csv')\n",
    "\n",
    "labels = labels.iloc[:,1:] #  remove useless first column\n",
    "print('2', training)\n",
    "n_users = 10\n",
    "n_seq = training.shape[0]/n_users\n",
    "n_features = training.shape[1]\n",
    "y = np.array(labels)\n",
    "X = np.array(training).reshape(n_users, n_seq, n_features)\n",
    "print('3', X, X.shape)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4 56  7  8  9]\n"
     ]
    }
   ],
   "source": [
    "list = [1,2,3,4,56,7,8,9]\n",
    "array = np.array(list)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "FILES = ['X_train.pkl', 'X_eval.pkl', 'y_train.pkl', 'y_eval.pkl']\n",
    "ARRAYS = [X_train, X_eval, y_train, y_eval]\n",
    "for idx, filename in enumerate(FILES):\n",
    "    with open(\"pickels/\"+filename, 'wb') as f:\n",
    "        pickle.dump(ARRAYS[idx], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model:\n",
    "Note the Stacked LSTMs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached Keras-2.1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/envs/py2env/lib/python2.7/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /usr/local/envs/py2env/lib/python2.7/site-packages (from keras)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.1.5\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "def model_fn(\n",
    "    n_seq, n_features, \n",
    "    lstm1_nodes=10, lstm2_nodes=10, mlp1_nodes=10\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm1_nodes, input_shape=(n_seq, n_features), return_sequences=True))\n",
    "    model.add(LSTM(lstm2_nodes))\n",
    "    model.add(Dense(mlp1_nodes, activation='relu', name='last_layer'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model Locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_6 to have shape (1,) but got array with shape (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2f856d3afcf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_6 to have shape (1,) but got array with shape (0,)"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "model = model_fn(X.shape[1], X.shape[2])\n",
    "#print(X_eval) \n",
    "print(y_train)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE, epochs=3,\n",
    "    validation_data=(X_eval, X_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "rm -rf vehicles.tar.gz lstm_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${REPO}\n",
    "python -m trainer.task \\\n",
    "   --train_data_paths=\"${REPO}/training.csv\" \\\n",
    "   --eval_data_paths=${REPO}/.csv  \\\n",
    "   --output_dir=${REPO}/vehicles_trained \\\n",
    "   --num_epochs=10 \\\n",
    "   --job-dir=./tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!ls $REPO/vehicles_trained/export/Servo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%writefile ./test.json\n",
    "{\"ACCELERATION\": 0.3424933,\"PITCH\": 0.4929889823,\"ROLL\": 0.999398298932,\"YAW\": 0.103000023}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "model_dir=$(ls ${REPO}/vehicles_trained/export/Servo/)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${REPO}/vehilces_trained/export/Servo/${model_dir} \\\n",
    "    --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "rm -rf vehicles.tar.gz vehicles_trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${REPO}/econsumption/trainer \\\n",
    "   -- \\\n",
    "   --train_data_paths=${REPO}/vehicles-train.csv \\\n",
    "   --eval_data_paths=${REPO}/vehicles-valid.csv  \\\n",
    "   --num_epochs=10 \\\n",
    "   --output_dir=${REPO}/vehicles_trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('{}/vehicles_trained'.format(REPO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print 'Stopped TensorBoard with pid {}'.format(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!ls $REPO/vehicles_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "model_dir=$(ls ${REPO}/vehicles_trained/export/Servo)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${REPO}/vehilces_trained/export/Servo/${model_dir} \\\n",
    "    --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/vehilce-health-status/neural-net\n",
    "gsutil -m cp ${REPO}/*.csv gs://${BUCKET}/vehilce-health-status/neural-net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/vehilce-health-status/neural-net/vehicles_trained\n",
    "JOBNAME=vehicles_health_demo_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${REPO}/econsumption/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --runtime-version=1.0 \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/vehilce-health-status/neural-net/vehicles-train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/vehilce-health-status/neural-net/vehicles-valid*\"  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --num_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
