{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hiddenCell": true
   },
   "outputs": [],
   "source": [
    "! pip install keras tensorflow-serving-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tf.__version__\n",
    "# If not working use tensorflow 1.2 (as of 18.01.2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keras model\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "# Keras layers can be called on TensorFlow tensors:\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=784))  # fully-connected layer with 128 units and ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training and test data\n",
    "from keras.datasets import mnist\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "from time import time\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                   callbacks=[tensorboard])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hidden layer with 128 nodes test acc: 9.796\n",
    "# two hidden layers with 128(relu) 128(relu) nodes test acc: 0.981\n",
    "# two hidden layers with 128(relu), 128(smax) nodes test acc: 0.973\n",
    "# two hidden layers with 512(relu), 128(relu) nodes test acc: 0.983, val_acc: 0.9834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how the MNIST labes and data looks like\n",
    "#print(y_test[800])\n",
    "#print(x_test[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as .pb (proto buffer)\n",
    "\n",
    "K.set_learning_phase(0)  # all new operations will be in test mode from now on\n",
    "\n",
    "from keras.models import model_from_config\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "\n",
    "###EXPORT Part\n",
    "export_path = \"gs://mkt-cloudml-jumpstart-christian/model_2_512_2\"\n",
    "#def to_savedmodel(model, export_path):\n",
    "\"\"\"Convert the Keras HDF5 model into TensorFlow SavedModel.\"\"\"\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "signature = predict_signature_def(inputs={'input': model.inputs[0]},\n",
    "                                    outputs={'income': model.outputs[0]})\n",
    "\n",
    "with K.get_session() as sess:\n",
    "   builder.add_meta_graph_and_variables(\n",
    "        sess=sess,\n",
    "        tags=[tag_constants.SERVING],\n",
    "        signature_def_map={\n",
    "            signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature}\n",
    "   )\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get credentials for ML Engine calls\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "\n",
    "ml = discovery.build('ml','v1', credentials=credentials)\n",
    "projectID = 'projects/{}'.format('mkt-cloudml-jumpstart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ml_engine model\n",
    "model_name = 'mnist_keras_test1'\n",
    "\n",
    "# Use new versions instead\n",
    "\"\"\"\n",
    "requestDict = {'name': model_name,\n",
    "               'description': 'Keras mnist classifier'}\n",
    "try:\n",
    "    response = ml.projects().models().create(parent=projectID,\n",
    "                                         body=requestDict).execute()\n",
    "    ml_model = response\n",
    "    print(response)\n",
    "except errors.HttpError, err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest version\n",
    "# List ml_engine model version\n",
    "requestDict = { }\n",
    "\n",
    "model_path = projectID + \"/models/\" + model_name\n",
    "try:\n",
    "    response = ml.projects().models().versions().list(parent=model_path).execute()\n",
    "    print(response)\n",
    "    for vers in response[\"versions\"]:\n",
    "      print(vers[\"name\"])\n",
    " \n",
    "except errors.HttpError, err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model version. Check the details:')\n",
    "    print(err._get_reason())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ml_engine model version\n",
    "version_name = \"v3\"\n",
    "requestDict = { \"name\": version_name,\n",
    "                \"description\": \"521(relu),128(relu),10(smax) - RMSprop\",\n",
    "                \"deploymentUri\": export_path\n",
    "              }\n",
    "\n",
    "model_path = projectID + \"/models/\" + model_name\n",
    "try:\n",
    "    response = ml.projects().models().versions().create(parent=model_path ,\n",
    "                                         body=requestDict).execute()\n",
    "    print(response)\n",
    "except errors.HttpError, err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model version. Check the details:')\n",
    "    print(err._get_reason())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update ml_engine model version to be the default\n",
    "\n",
    "version_path = projectID + \"/models/\" + model_name + \"/versions/\" + version_name\n",
    "\n",
    "try:\n",
    "    response = ml.projects().models().versions().setDefault(name=version_path, body={}).execute()\n",
    "    print(response)\n",
    "except errors.HttpError, err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model version. Check the details:')\n",
    "    print(err._get_reason())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do online predition\n",
    "ind = 6585\n",
    "requestDict = { \"instances\": [ x_test[ind].tolist() ]\n",
    "              }\n",
    "#print(requestDict)\n",
    "model_path = projectID + \"/models/\" + model_name\n",
    "try:\n",
    "    response = ml.projects().predict(name=model_path ,\n",
    "                                         body=requestDict).execute()\n",
    "    print(response)\n",
    "except errors.HttpError, err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error predicting. Check the details:')\n",
    "    print(err._get_reason())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get result\n",
    "\n",
    "results_list = response[\"predictions\"][0][\"income\"]\n",
    "index = results_list.index(max(results_list))\n",
    "print('Predicted digit: ' + str(index) + ' with a confidence of: ' + str(results_list[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the actual input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pixels = np.array(x_test[ind], dtype='float32')\n",
    "\n",
    "# Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "pixels = pixels.reshape((28, 28))\n",
    "\n",
    "# Plot\n",
    "label = ind\n",
    "plt.title('Label is {label}'.format(label=label))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a number of online predictions\n",
    "from random import randint\n",
    "\n",
    "for x in range(0, 100):\n",
    "    i = randint(0, 9999)\n",
    "    requestDict = { \"instances\": [ x_test[i].tolist() ]\n",
    "                  }\n",
    "                   \n",
    "    try:\n",
    "        response = ml.projects().predict(name=model_path ,\n",
    "                                         body=requestDict).execute()\n",
    "        results_list = response[\"predictions\"][0][\"income\"]\n",
    "        index = results_list.index(max(results_list))\n",
    "        print('For index: ' + str(i) + ' predicted digit is: ' + str(index) + ' with a confidence of: ' + str(results_list[index]))\n",
    "    except errors.HttpError, err:\n",
    "        # Something went wrong, print out some information.\n",
    "        print('There was an error predicting. Check the details:')\n",
    "        print(err._get_reason())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a number of online predictions\n",
    "from random import randint\n",
    "\n",
    "a = randint(0, 9999)\n",
    "b = randint(0, 9999)\n",
    "print(y_test[a]) \n",
    "print(y_test[b])\n",
    "\n",
    "requestDict = { \"instances\": [ \n",
    "                               { \n",
    "                                 \"input\": x_test[a].tolist()\n",
    "                               },\n",
    "                               { \n",
    "                                 \"input\": x_test[b].tolist()\n",
    "                               }\n",
    "                             ]\n",
    "                  }\n",
    "                   \n",
    "try:\n",
    "        response = ml.projects().predict(name=model_path ,\n",
    "                                         body=requestDict).execute()\n",
    "        #print(response)\n",
    "        predictions_list = response[\"predictions\"]\n",
    "        for i, prediction in enumerate(predictions_list):\n",
    "          results_list = prediction[\"income\"]\n",
    "          index = results_list.index(max(results_list))\n",
    "          print(' For index ' + str(i) + ' the predicted digit is ' + str(index) + ' with a confidence of: ' + str(results_list[index]))\n",
    "except errors.HttpError, err:\n",
    "        # Something went wrong, print out some information.\n",
    "        print('There was an error predicting. Check the details:')\n",
    "        print(err._get_reason())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
