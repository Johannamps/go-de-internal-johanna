{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-1.6.0-cp27-cp27mu-manylinux1_x86_64.whl (45.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 45.9MB 12kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.7.0,>=1.6.0 (from tensorflow)\n",
      "  Downloading tensorboard-1.6.0-py2-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 198kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.13.3 (from tensorflow)\n",
      "  Downloading numpy-1.14.1-cp27-cp27mu-manylinux1_x86_64.whl (12.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.1MB 48kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already up-to-date: mock>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow)\n",
      "Requirement already up-to-date: wheel in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading astor-0.6.2-py2.py3-none-any.whl\n",
      "Requirement already up-to-date: backports.weakref>=1.0rc1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-1.1.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading gast-0.2.0.tar.gz\n",
      "Requirement already up-to-date: enum34>=1.1.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading grpcio-1.10.0-cp27-cp27mu-manylinux1_x86_64.whl (7.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.4MB 78kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.10.0 (from tensorflow)\n",
      "  Downloading six-1.11.0-py2.py3-none-any.whl\n",
      "Requirement already up-to-date: absl-py>=0.1.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow)\n",
      "Collecting protobuf>=3.4.0 (from tensorflow)\n",
      "  Downloading protobuf-3.5.1-cp27-cp27mu-manylinux1_x86_64.whl (6.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.4MB 91kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting futures>=3.1.1; python_version < \"3\" (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n",
      "  Downloading futures-3.2.0-py2-none-any.whl\n",
      "Requirement already up-to-date: markdown>=2.6.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n",
      "Collecting bleach==1.5.0 (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n",
      "  Downloading bleach-1.5.0-py2.py3-none-any.whl\n",
      "Requirement already up-to-date: werkzeug>=0.11.10 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n",
      "  Downloading html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 583kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: pbr>=0.11 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow)\n",
      "Collecting funcsigs>=1 (from mock>=2.0.0->tensorflow)\n",
      "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already up-to-date: setuptools in /usr/local/envs/py2env/lib/python2.7/site-packages (from protobuf>=3.4.0->tensorflow)\n",
      "Building wheels for collected packages: termcolor, gast, html5lib\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/de/f7/bf/1bcac7bf30549e6a4957382e2ecab04c88e513117207067b03\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/8e/fa/d6/77dd17d18ea23fd7b860e02623d27c1be451521af40dd4a13e\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/6f/85/6c/56b8e1292c6214c4eb73b9dda50f53e8e977bf65989373c962\n",
      "Successfully built termcolor gast html5lib\n",
      "Installing collected packages: futures, six, html5lib, bleach, protobuf, numpy, tensorboard, astor, termcolor, gast, grpcio, tensorflow, funcsigs\n",
      "  Found existing installation: futures 3.0.5\n",
      "    Uninstalling futures-3.0.5:\n",
      "      Successfully uninstalled futures-3.0.5\n",
      "  Found existing installation: six 1.10.0\n",
      "    Uninstalling six-1.10.0:\n",
      "      Successfully uninstalled six-1.10.0\n",
      "  Found existing installation: html5lib 1.0.1\n",
      "    Uninstalling html5lib-1.0.1:\n",
      "      Successfully uninstalled html5lib-1.0.1\n",
      "  Found existing installation: bleach 2.1.2\n",
      "    Uninstalling bleach-2.1.2:\n",
      "      Successfully uninstalled bleach-2.1.2\n",
      "  Found existing installation: protobuf 3.2.0\n",
      "    Uninstalling protobuf-3.2.0:\n",
      "      Successfully uninstalled protobuf-3.2.0\n",
      "  Found existing installation: numpy 1.14.0\n",
      "    Uninstalling numpy-1.14.0:\n",
      "      Successfully uninstalled numpy-1.14.0\n",
      "  Found existing installation: grpcio 1.9.1\n",
      "    Uninstalling grpcio-1.9.1:\n",
      "      Successfully uninstalled grpcio-1.9.1\n",
      "  Found existing installation: tensorflow 1.5.0\n",
      "    Uninstalling tensorflow-1.5.0:\n",
      "      Successfully uninstalled tensorflow-1.5.0\n",
      "  Found existing installation: funcsigs 1.0.0\n",
      "    Uninstalling funcsigs-1.0.0:\n",
      "      Successfully uninstalled funcsigs-1.0.0\n",
      "Successfully installed astor-0.6.2 bleach-1.5.0 funcsigs-1.0.2 futures-3.2.0 gast-0.2.0 grpcio-1.10.0 html5lib-0.9999999 numpy-1.14.1 protobuf-3.5.1 six-1.11.0 tensorboard-1.6.0 tensorflow-1.6.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print tf.__version__\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Baseline model and compute its RSME </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('averageEconsumption = ', 0.010274811520608038)\n",
      "Train RMSE = 0.149345829532\n",
      "Valid RMSE = 0.148660663726\n",
      "Test RMSE = 0.146238892905\n"
     ]
    }
   ],
   "source": [
    "def estimate_stress(df):\n",
    "  columns = [abs(df['ACCELERATION']), abs(df['PITCH']), abs(df['ROLL']), abs(df['YAW'])]\n",
    "  stress_level = sum(columns)/4\n",
    "  return stress_level\n",
    "\n",
    "def compute_rmse(actual, predicted):\n",
    "  return np.sqrt(np.mean((actual-predicted)**2))\n",
    "\n",
    "def print_rmse(df, econsump, name):\n",
    "  print (\"{1} RMSE = {0}\".format(compute_rmse(df['ECONSUMPTION'], econsump*estimate_stress(df)), name))\n",
    "\n",
    "FEATURES = ['ACCELERATION', 'PITCH','ROLL','YAW']\n",
    "TARGET = 'ECONSUMPTION'\n",
    "columns = list([TARGET])\n",
    "columns.extend(FEATURES) # in CSV, target is the first column, after the features\n",
    "columns.append('key')\n",
    "df_train = pd.read_csv('vehicles-train.csv', header=None, names=columns)\n",
    "df_valid = pd.read_csv('vehicles-valid.csv', header=None, names=columns)\n",
    "df_test = pd.read_csv('vehicles-test.csv', header=None, names=columns)\n",
    "econsump = df_train['ECONSUMPTION'].mean() * estimate_stress(df_train).mean()/4\n",
    "print (\"averageEconsumption = \", econsump)\n",
    "print_rmse(df_train, econsump, 'Train')\n",
    "print_rmse(df_valid, econsump, 'Valid')\n",
    "print_rmse(df_test, econsump, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> ML Regression with Neural Network </h1>\n",
    "\n",
    "Now lets try and run a smarter model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'data-preparation.ipynb',\n",
       " 'vehicles-valid.csv',\n",
       " 'test.json',\n",
       " 'vehicles-test.csv',\n",
       " 'vehicles-train.csv',\n",
       " 'econsumption',\n",
       " 'linear-regression-with-neural-networks.ipynb']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT = 'go-de-internal'\n",
    "BUCKET = 'go-de-internal-johanna'\n",
    "REGION = 'europe-west1'\n",
    "REPO = \"/content/datalab/demo-cases/vehilce-health-status\"\n",
    "os.listdir(REPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['REPO'] = REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorizing the Cloud ML Service account service-462605511119@cloud-ml.google.com.iam.gserviceaccount.com to access files in go-de-internal-johanna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   133    0   133    0     0    151      0 --:--:-- --:--:-- --:--:--   151\r",
      "100   133    0   133    0     0    151      0 --:--:-- --:--:-- --:--:--   151\n",
      "Updated default ACL on gs://go-de-internal-johanna/\n",
      "Updated ACL on gs://go-de-internal-johanna/churn-prediction/\n",
      "Updated ACL on gs://go-de-internal-johanna/churn-prediction/mv_ab_model_ads_build_sep.csv\n",
      "Updated ACL on gs://go-de-internal-johanna/flight-time-estimate/\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/lindeshow-case-data-all.csv\n",
      "Updated ACL on gs://go-de-internal-johanna/vehilce-health-status/\n",
      "Updated ACL on gs://go-de-internal-johanna/pattern-recognition/\n",
      "Updated ACL on gs://go-de-internal-johanna/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print response['serviceAccount']\")\n",
    "\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "\r\n",
      "# Copyright 2017 Google Inc. All Rights Reserved.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
      "# you may not use this file except in compliance with the License.\r\n",
      "# You may obtain a copy of the License at\r\n",
      "#\r\n",
      "#      http://www.apache.org/licenses/LICENSE-2.0\r\n",
      "#\r\n",
      "# Unless required by applicable law or agreed to in writing, software\r\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
      "# See the License for the specific language governing permissions and\r\n",
      "# limitations under the License.\r\n",
      "\r\n",
      "from __future__ import absolute_import\r\n",
      "from __future__ import division\r\n",
      "from __future__ import print_function\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.contrib import layers\r\n",
      "import tensorflow.contrib.learn as tflearn\r\n",
      "from tensorflow.contrib import metrics\r\n",
      "\r\n",
      "\r\n",
      "tf.logging.set_verbosity(tf.logging.INFO)\r\n",
      "\r\n",
      "CSV_COLUMNS = ['ECONSUMPTION', 'ACCELERATION','PITCH','ROLL','YAW', 'key']\r\n",
      "\r\n",
      "LABEL_COLUMN = 'ECONSUMPTION'\r\n",
      "\r\n",
      "DEFAULTS = [[5.0], [0.0], [0.0], [0.0], [0.0], ['nokey']]\r\n",
      "\r\n",
      "# These are the raw input columns, and will be provided for prediction also\r\n",
      "INPUT_COLUMNS = [\r\n",
      "    layers.real_valued_column('ACCELERATION'),\r\n",
      "    layers.real_valued_column('PITCH'),\r\n",
      "    layers.real_valued_column('ROLL'),\r\n",
      "    layers.real_valued_column('YAW'),\r\n",
      "]\r\n",
      "\r\n",
      "def build_estimator(model_dir, hidden_units):\r\n",
      "  (accel, pitch, roll, yaw) = INPUT_COLUMNS \r\n",
      "  return tf.contrib.learn.DNNRegressor(\r\n",
      "      model_dir=model_dir,\r\n",
      "      feature_columns=[accel, pitch, roll, yaw],  # as-is\r\n",
      "      hidden_units=hidden_units or [128, 32, 4])\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn():\r\n",
      "    feature_placeholders = {\r\n",
      "        column.name: tf.placeholder(tf.float32, [None]) for column in INPUT_COLUMNS\r\n",
      "    }\r\n",
      "    features = {\r\n",
      "      key: tf.expand_dims(tensor, -1)\r\n",
      "      for key, tensor in feature_placeholders.items()\r\n",
      "    }\r\n",
      "    return tflearn.utils.input_fn_utils.InputFnOps(\r\n",
      "      features,\r\n",
      "      None,\r\n",
      "      feature_placeholders\r\n",
      "    )\r\n",
      "\r\n",
      "def generate_csv_input_fn(filename, num_epochs=None, batch_size=512, mode=tf.contrib.learn.ModeKeys.TRAIN):\r\n",
      "  def _input_fn():\r\n",
      "    # could be a path to one file or a file pattern.\r\n",
      "    input_file_names = tf.train.match_filenames_once(filename)\r\n",
      "    #input_file_names = [filename]\r\n",
      "\r\n",
      "    filename_queue = tf.train.string_input_producer(\r\n",
      "        input_file_names, num_epochs=num_epochs, shuffle=True)\r\n",
      "    reader = tf.TextLineReader()\r\n",
      "    _, value = reader.read_up_to(filename_queue, num_records=batch_size)\r\n",
      "\r\n",
      "    value_column = tf.expand_dims(value, -1)\r\n",
      "\r\n",
      "    columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\r\n",
      "\r\n",
      "    features = dict(zip(CSV_COLUMNS, columns))\r\n",
      "\r\n",
      "    label = features.pop(LABEL_COLUMN)\r\n",
      "\r\n",
      "    return features, label\r\n",
      "\r\n",
      "  return _input_fn\r\n",
      "\r\n",
      "\r\n",
      "def get_eval_metrics():\r\n",
      "  return {\r\n",
      "     'rmse': tflearn.MetricSpec(metric_fn=metrics.streaming_root_mean_squared_error),\r\n",
      "  }\r\n"
     ]
    }
   ],
   "source": [
    "!cat econsumption/trainer/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011634026758261544,0.020811654526534856,0.43367346938775514,0.3654822335025381,0.8838383838383839,0\n",
      "0.16021716849948758,0.008324661810613941,0.3928571428571429,0.4974619289340102,0.4292929292929293,0\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "head -1 $REPO/vehicles-train.csv\n",
    "head -1 $REPO/vehicles-valid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Running the Python module from the command-line </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0571682690>, '_model_dir': '/content/datalab/demo-cases/vehilce-health-status/vehicles_trained/', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-05-13:55:40\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-05-13:55:40\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 0.01680103, rmse = 0.12964079\n",
      "INFO:tensorflow:Validation (step 1): loss = 0.01680103, global_step = 1, rmse = 0.12964079\n",
      "INFO:tensorflow:loss = 0.028017933, step = 1\n",
      "INFO:tensorflow:global_step/sec: 61.0721\n",
      "INFO:tensorflow:loss = 0.009177851, step = 101 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.7063\n",
      "INFO:tensorflow:loss = 0.012353345, step = 201 (1.394 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 210 into /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.012486277.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-05-13:55:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt-210\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-05-13:55:44\n",
      "INFO:tensorflow:Saving dict for global step 210: global_step = 210, loss = 0.0115865795, rmse = 0.10731637\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt-210\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/export/Servo/temp-1520258144/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf vehicles.tar.gz vehicles_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${REPO}/econsumption\n",
    "python -m trainer.task \\\n",
    "   --train_data_paths=\"${REPO}/vehicles-train*\" \\\n",
    "   --eval_data_paths=${REPO}/vehicles-valid.csv  \\\n",
    "   --output_dir=${REPO}/vehicles_trained \\\n",
    "   --num_epochs=10 \\\n",
    "   --job-dir=./tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520258144\r\n"
     ]
    }
   ],
   "source": [
    "!ls $REPO/vehicles_trained/export/Servo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./test.json\n"
     ]
    }
   ],
   "source": [
    "%writefile ./test.json\n",
    "{\"ACCELERATION\": 0.3424933,\"PITCH\": 0.4929889823,\"ROLL\": 0.999398298932,\"YAW\": 0.103000023}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.local.predict) /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Traceback (most recent call last):\n",
      "  File \"lib/googlecloudsdk/command_lib/ml_engine/local_predict.py\", line 111, in <module>\n",
      "    main()\n",
      "  File \"lib/googlecloudsdk/command_lib/ml_engine/local_predict.py\", line 106, in main\n",
      "    instances=instances)\n",
      "  File \"/tools/google-cloud-sdk/lib/third_party/cloud_ml_engine_sdk/prediction/prediction_lib.py\", line 1304, in local_predict\n",
      "    client = create_client(framework, model_dir, tags)\n",
      "  File \"/tools/google-cloud-sdk/lib/third_party/cloud_ml_engine_sdk/prediction/prediction_lib.py\", line 1242, in create_client\n",
      "    return create_client_fn(model_path, tags)\n",
      "  File \"/tools/google-cloud-sdk/lib/third_party/cloud_ml_engine_sdk/prediction/prediction_lib.py\", line 1102, in create_tf_session_client\n",
      "    return SessionClient(*load_model(model_dir, tags))\n",
      "  File \"/tools/google-cloud-sdk/lib/third_party/cloud_ml_engine_sdk/prediction/prediction_lib.py\", line 448, in load_model\n",
      "    \"Cloud ML only supports TF 1.0 or above and models \"\n",
      "prediction_lib.PredictionError: Failed to load model: Cloud ML only supports TF 1.0 or above and models saved in SavedModel format. (Error code: 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "model_dir=$(ls ${REPO}/vehicles_trained/export/Servo)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${REPO}/vehilces_trained/export/Servo/${model_dir} \\\n",
    "    --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Running locally using gcloud </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4195efcd50>, '_model_dir': '/content/datalab/demo-cases/vehilce-health-status/vehicles_trained/', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': u'cloud', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-05-14:50:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-05-14:50:21\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 0.014481202, rmse = 0.120014064\n",
      "INFO:tensorflow:Validation (step 1): loss = 0.014481202, global_step = 1, rmse = 0.120014064\n",
      "INFO:tensorflow:loss = 0.018711051, step = 1\n",
      "INFO:tensorflow:global_step/sec: 67.2331\n",
      "INFO:tensorflow:loss = 0.00849135, step = 101 (1.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5043\n",
      "INFO:tensorflow:loss = 0.011607766, step = 201 (1.141 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 210 into /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.011422092.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-05-14:50:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt-210\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-05-14:50:24\n",
      "INFO:tensorflow:Saving dict for global step 210: global_step = 210, loss = 0.0106924875, rmse = 0.10307187\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/model.ckpt-210\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/demo-cases/vehilce-health-status/vehicles_trained/export/Servo/temp-1520261424/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf vehicles.tar.gz vehicles_trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${REPO}/econsumption/trainer \\\n",
    "   -- \\\n",
    "   --train_data_paths=${REPO}/vehicles-train.csv \\\n",
    "   --eval_data_paths=${REPO}/vehicles-valid.csv  \\\n",
    "   --num_epochs=10 \\\n",
    "   --output_dir=${REPO}/vehicles_trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 20213. Click <a href=\"/_proxy/48249/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20213"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('{}/vehicles_trained'.format(REPO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 20213\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print 'Stopped TensorBoard with pid {}'.format(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/content/datalab/democases-go-reply-internal/vehicle-health-status/vehicles_trained': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls $REPO/vehicles_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.local.predict) /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Traceback (most recent call last):\n",
      "  File \"lib/googlecloudsdk/command_lib/ml_engine/local_predict.py\", line 111, in <module>\n",
      "    main()\n",
      "  File \"lib/googlecloudsdk/command_lib/ml_engine/local_predict.py\", line 106, in main\n",
      "    instances=instances)\n",
      "  File \"/tools/google-cloud-sdk/lib/third_party/cloud_ml_engine_sdk/prediction/prediction_lib.py\", line 1304, in local_predict\n",
      "    client = create_client(framework, model_dir, tags)\n",
      "  File \"/tools/google-cloud-sdk/lib/third_party/cloud_ml_engine_sdk/prediction/prediction_lib.py\", line 1242, in create_client\n",
      "    return create_client_fn(model_path, tags)\n",
      "  File \"/tools/google-cloud-sdk/lib/third_party/cloud_ml_engine_sdk/prediction/prediction_lib.py\", line 1102, in create_tf_session_client\n",
      "    return SessionClient(*load_model(model_dir, tags))\n",
      "  File \"/tools/google-cloud-sdk/lib/third_party/cloud_ml_engine_sdk/prediction/prediction_lib.py\", line 448, in load_model\n",
      "    \"Cloud ML only supports TF 1.0 or above and models \"\n",
      "prediction_lib.PredictionError: Failed to load model: Cloud ML only supports TF 1.0 or above and models saved in SavedModel format. (Error code: 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "model_dir=$(ls ${REPO}/vehicles_trained/export/Servo)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${REPO}/vehilces_trained/export/Servo/${model_dir} \\\n",
    "    --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Submit training job using gcloud </h2>\n",
    "\n",
    "First copy the training data to the cloud.  Then, launch a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go-de-internal-johanna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Copying file:///content/datalab/demo-cases/vehilce-health-status/vehicles-test.csv [Content-Type=text/csv]...\n",
      "Copying file:///content/datalab/demo-cases/vehilce-health-status/vehicles-train.csv [Content-Type=text/csv]...\n",
      "/ [0 files][    0.0 B/224.9 KiB]                                                \r",
      "/ [0/3 files][    0.0 B/  1.5 MiB]   0% Done                                    \r",
      "Copying file:///content/datalab/demo-cases/vehilce-health-status/vehicles-valid.csv [Content-Type=text/csv]...\n",
      "/ [0/3 files][    0.0 B/  1.5 MiB]   0% Done                                    \r",
      "/ [1/3 files][  1.5 MiB/  1.5 MiB]  99% Done                                    \r",
      "/ [2/3 files][  1.5 MiB/  1.5 MiB]  99% Done                                    \r",
      "/ [3/3 files][  1.5 MiB/  1.5 MiB] 100% Done                                    \r\n",
      "Operation completed over 3 objects/1.5 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/vehilce-health-status/neural-net\n",
    "gsutil -m cp ${REPO}/*.csv gs://${BUCKET}/vehilce-health-status//neural-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://go-de-internal-johanna/vehilce-health-status/neural-net/vehicles_trained europe-west1 vehicles_health_demo_180305_145424\n",
      "jobId: vehicles_health_demo_180305_145424\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "/tools/google-cloud-sdk/lib/googlecloudsdk/core/util/files.py:622: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  for chunk in iter(lambda: fp.read(4096), ''):\n",
      "Job [vehicles_health_demo_180305_145424] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe vehicles_health_demo_180305_145424\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs vehicles_health_demo_180305_145424\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/vehilce-health-status/neural-net/vehicles_trained\n",
    "JOBNAME=vehicles_health_demo_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${REPO}/econsumption/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --runtime-version=1.0 \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/econsumption/smallinput/vehicles-train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/econsumption/smallinput/vehicles-valid*\"  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --num_epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Deploy model </h1>\n",
    "\n",
    "Find out the actual name of the subdirectory where the model is stored and use it to deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/econsumption/smallinput/vehicles_trained/export/Servo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying econsumption v1 from  ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n",
      "Created ml engine model [projects/go-de-internal/models/econsumption].\n",
      "ERROR: (gcloud.ml-engine.versions.create) argument --origin: expected one argument\n",
      "Usage: gcloud ml-engine versions create VERSION --model=MODEL [optional flags]\n",
      "  optional flags may be  --async | --config | --description | --help |\n",
      "                         --labels | --origin | --runtime-version |\n",
      "                         --staging-bucket\n",
      "\n",
      "For detailed information on this command and its flags, run:\n",
      "  gcloud ml-engine versions create --help\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"econsumption\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/econsumption/smallinput/vehicles_trained/export/Servo | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Prediction </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.predict) HTTP request failed. Response: {\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"Field: name Error: The specified model version was not found.\",\n",
      "    \"status\": \"NOT_FOUND\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\n",
      "        \"fieldViolations\": [\n",
      "          {\n",
      "            \"field\": \"name\",\n",
      "            \"description\": \"The specified model version was not found.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine predict --model=econsumption --version=v1 --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 404 when requesting https://ml.googleapis.com/v1/projects/go-de-internal/models/econsumption/versions/v1:predict?alt=json returned \"Field: name Error: The specified model version was not found.\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-55b3d118de59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'projects/%s/models/%s/versions/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPROJECT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'econsumption'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"response={0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/oauth2client/util.pyc\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/googleapiclient/http.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 404 when requesting https://ml.googleapis.com/v1/projects/go-de-internal/models/econsumption/versions/v1:predict?alt=json returned \"Field: name Error: The specified model version was not found.\">"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials,\n",
    "            discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "\n",
    "request_data = {'instances':\n",
    "  [\n",
    "      {\n",
    "        'ACCELERATION': 0.3424933,\n",
    "        'PITCH': 0.49298898232,\n",
    "        'ROLL': 0.999398298932,\n",
    "        'YAW': 0.103000023,\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "\n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'econsumption', 'v1')\n",
    "response = api.projects().predict(body=request_data, name=parent).execute()\n",
    "print \"response={0}\".format(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Create hyper-parameter tuning </h1>\n",
    "\n",
    "The file specifies the search region in parameter space.  Cloud MLE carries out a smart search algorithm within these constraints (i.e. it does not try out every single value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  parser.add_argument(\r\n",
      "      '--train_data_paths',\r\n",
      "      help='GCS or local path to training data',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--num_epochs',\r\n",
      "      help=\"\"\"\\\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--train_batch_size',\r\n",
      "      help='Batch size for training steps',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--eval_batch_size',\r\n",
      "      help='Batch size for evaluation steps',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--train_steps',\r\n",
      "      help=\"\"\"\\\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--eval_steps',\r\n",
      "      help='Number of steps to run evalution for at each checkpoint',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--eval_data_paths',\r\n",
      "      help='GCS or local path to evaluation data',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--hidden_units',\r\n",
      "      help='List of hidden layer sizes to use for DNN feature columns',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--output_dir',\r\n",
      "      help='GCS location to write checkpoints and export models',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--job-dir',\r\n",
      "      help='this model ignores this field, but it is required by gcloud',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--eval_delay_secs',\r\n",
      "      help='How long to wait before running first evaluation',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--min_eval_frequency',\r\n",
      "      help='Minimum number of training steps between evaluations',\r\n",
      "--\r\n",
      "  parser.add_argument(\r\n",
      "      '--format',\r\n",
      "      help='Is the input data format csv or tfrecord?',\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A 2 add_argument econsumption/trainer/task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_eval_metrics():\r\n",
      "  return {\r\n",
      "     'rmse': tflearn.MetricSpec(metric_fn=metrics.streaming_root_mean_squared_error),\r\n",
      "  }\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A 5 eval_metric econsumption/trainer/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 1\n",
    "    params:\n",
    "    - parameterName: train_batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 64\n",
    "      maxValue: 512\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: nbuckets\n",
    "      type: INTEGER\n",
    "      minValue: 10\n",
    "      maxValue: 20\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"128 32\", \"256 128 16\", \"64 64 64 8\"]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go-de-internal-johanna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Copying file:///content/datalab/demo-cases/vehilce-health-status/vehicles-test.csv [Content-Type=text/csv]...\n",
      "Copying file:///content/datalab/demo-cases/vehilce-health-status/vehicles-train.csv [Content-Type=text/csv]...\n",
      "/ [0 files][    0.0 B/224.9 KiB]                                                \r",
      "/ [0/3 files][    0.0 B/  1.5 MiB]   0% Done                                    \r",
      "Copying file:///content/datalab/demo-cases/vehilce-health-status/vehicles-valid.csv [Content-Type=text/csv]...\n",
      "/ [0/3 files][    0.0 B/  1.5 MiB]   0% Done                                    \r",
      "/ [1/3 files][  1.5 MiB/  1.5 MiB]  99% Done                                    \r",
      "/ [2/3 files][  1.5 MiB/  1.5 MiB]  99% Done                                    \r",
      "/ [3/3 files][  1.5 MiB/  1.5 MiB] 100% Done                                    \r\n",
      "Operation completed over 3 objects/1.5 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo $BUCKET\n",
    "gsutil -m rm -rf gs://${BUCKET}/vehilce-health-status/hyper-param\n",
    "gsutil -m cp ${REPO}/*.csv gs://${BUCKET}/vehilce-health-status/hyper-param/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://storage-democases-go-reply-internal/econsumption/hyper_param/vehicles_trained us-central1 vehicles_health_demo_hyper_param_180226_153810\n",
      "jobId: vehicles_health_demo_hyper_param_180226_153810\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "/tools/google-cloud-sdk/lib/googlecloudsdk/core/util/files.py:622: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  for chunk in iter(lambda: fp.read(4096), ''):\n",
      "Job [vehicles_health_demo_hyper_param_180226_153810] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe vehicles_health_demo_hyper_param_180226_153810\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs vehicles_health_demo_hyper_param_180226_153810\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/vehilce-health-status/hyper-param/vehicles_trained\n",
    "JOBNAME=vehicles_health_demo_hyper_param_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${REPO}/econsumption/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=STANDARD_1 \\\n",
    "   --runtime-version=1.2 \\\n",
    "   --config=hyperparam.yaml \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://$BUCKET/vehilce-health-status/hyper-param/vehicles-train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/vehilce-health-status/hyper-param/vehicles-valid*\"  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --num_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
